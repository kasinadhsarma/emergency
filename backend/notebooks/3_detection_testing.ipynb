{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emergency Vehicle Detection Testing\n",
    "\n",
    "This notebook tests the trained YOLOv8 model on various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.detection import VehicleDetector\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize detector with custom model\n",
    "detector = VehicleDetector(model_path='../models/yolov8_custom.pt')\n",
    "print(f\"Model loaded on device: {detector.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test on Single Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_detection(image_path):\n",
    "    \"\"\"Visualize detections on a single image\"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get detections\n",
    "    detections = detector.detect_frame(img)\n",
    "    \n",
    "    # Draw detections\n",
    "    for det in detections:\n",
    "        bbox = det.bbox.astype(int)\n",
    "        label = f\"{det.class_name} {det.confidence:.2f}\"\n",
    "        \n",
    "        # Draw box\n",
    "        cv2.rectangle(\n",
    "            img, \n",
    "            (bbox[0], bbox[1]), \n",
    "            (bbox[2], bbox[3]),\n",
    "            (0, 255, 0), 2\n",
    "        )\n",
    "        \n",
    "        # Draw label\n",
    "        cv2.putText(\n",
    "            img, label,\n",
    "            (bbox[0], bbox[1] - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5, (0, 255, 0), 2\n",
    "        )\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Detections in {Path(image_path).name}')\n",
    "    plt.show()\n",
    "    \n",
    "    return detections\n",
    "\n",
    "# Test on sample images from test set\n",
    "test_images = list(Path('../Dataset/prepared/test/images').glob('*.jpg'))[:5]\n",
    "for img_path in test_images:\n",
    "    detections = visualize_detection(img_path)\n",
    "    print(f\"\\nDetections in {img_path.name}:\")\n",
    "    for det in detections:\n",
    "        print(f\"- {det.class_name}: {det.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_performance(num_images=100):\n",
    "    \"\"\"Analyze detection performance on test set\"\"\"\n",
    "    test_images = list(Path('../Dataset/prepared/test/images').glob('*.jpg'))[:num_images]\n",
    "    \n",
    "    # Performance metrics\n",
    "    inference_times = []\n",
    "    confidence_scores = []\n",
    "    class_distributions = {}\n",
    "    \n",
    "    for img_path in tqdm(test_images, desc='Analyzing performance'):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        \n",
    "        # Measure inference time\n",
    "        start_time = time.time()\n",
    "        detections = detector.detect_frame(img)\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        inference_times.append(inference_time)\n",
    "        \n",
    "        for det in detections:\n",
    "            confidence_scores.append(det.confidence)\n",
    "            class_distributions[det.class_name] = class_distributions.get(det.class_name, 0) + 1\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('Detection Performance Analysis')\n",
    "    \n",
    "    # Inference time distribution\n",
    "    axes[0].hist(inference_times, bins=20)\n",
    "    axes[0].set_title('Inference Time Distribution')\n",
    "    axes[0].set_xlabel('Time (seconds)')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    \n",
    "    # Confidence score distribution\n",
    "    axes[1].hist(confidence_scores, bins=20)\n",
    "    axes[1].set_title('Confidence Score Distribution')\n",
    "    axes[1].set_xlabel('Confidence')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    \n",
    "    # Class distribution\n",
    "    classes = list(class_distributions.keys())\n",
    "    counts = list(class_distributions.values())\n",
    "    axes[2].bar(classes, counts)\n",
    "    axes[2].set_title('Detected Class Distribution')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(f\"Average inference time: {np.mean(inference_times):.3f}s\")\n",
    "    print(f\"Average confidence score: {np.mean(confidence_scores):.3f}\")\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for cls, count in class_distributions.items():\n",
    "        print(f\"- {cls}: {count}\")\n",
    "\n",
    "# Run performance analysis\n",
    "analyze_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Video Processing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_test_video(video_path, output_path=None):\n",
    "    \"\"\"Process a test video and visualize detections\"\"\"\n",
    "    if output_path:\n",
    "        detector.process_video_with_visualization(video_path, output_path)\n",
    "    else:\n",
    "        # Process without saving\n",
    "        frame_detections = []\n",
    "        for detections in detector.process_video(video_path):\n",
    "            frame_detections.append(len(detections))\n",
    "            \n",
    "        # Plot detection counts over time\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(frame_detections)\n",
    "        plt.title('Number of Detections per Frame')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Number of Detections')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Test on a sample video if available\n",
    "video_path = Path('../Dataset/test_videos/traffic.mp4')\n",
    "if video_path.exists():\n",
    "    process_test_video(\n",
    "        str(video_path),\n",
    "        output_path='../Dataset/test_videos/traffic_detected.mp4'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-time Detection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test real-time detection (press 'q' to quit)\n",
    "detector.start_realtime_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
