{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import yaml\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def count_images(dataset_path, classes):\n",
        "    \"\"\"Counts images for each class to check dataset balance.\"\"\"\n",
        "    counts = {class_name: 0 for class_name in classes}\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            counts[class_name] = len([img for img in os.listdir(class_path) if img.lower().endswith(('jpg', 'jpeg', 'png'))])\n",
        "    return counts\n",
        "\n",
        "def create_labels(img_path, class_id, subset, base_dir):\n",
        "    \"\"\"Create improved labels, ensuring fire engines have better detection coverage.\"\"\"\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "\n",
        "    if class_id == 1:\n",
        "        box_w = img_w * 0.7\n",
        "        box_h = img_h * 0.6\n",
        "    else:\n",
        "        box_w = img_w * 0.5\n",
        "        box_h = img_h * 0.5\n",
        "\n",
        "    x_center, y_center = 0.5, 0.5\n",
        "    w, h = box_w / img_w, box_h / img_h\n",
        "\n",
        "    label_path = os.path.join(base_dir, 'labels', subset, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
        "    with open(label_path, 'w') as f:\n",
        "        f.write(f\"{class_id} {x_center} {y_center} {w} {h}\\n\")\n",
        "\n",
        "def setup_yolo_directory():\n",
        "    base_dir = '/content/emergency_vehicles'\n",
        "    for subdir in ['images/train', 'images/val', 'labels/train', 'labels/val']:\n",
        "        os.makedirs(os.path.join(base_dir, subdir), exist_ok=True)\n",
        "    return base_dir\n",
        "\n",
        "def organize_dataset(dataset_path):\n",
        "    classes = {'Police': 0, 'Fire_Engine': 1, 'Ambulance': 2}\n",
        "    base_dir = setup_yolo_directory()\n",
        "    dataset_path = os.path.join(dataset_path, 'Dataset')\n",
        "\n",
        "    counts = count_images(dataset_path, classes)\n",
        "    print(\"Dataset class distribution:\", counts)\n",
        "\n",
        "    dataset_config = {\n",
        "        'path': base_dir,\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'names': list(classes.keys()),\n",
        "        'nc': len(classes)\n",
        "    }\n",
        "    with open(f'{base_dir}/dataset.yaml', 'w') as f:\n",
        "        yaml.dump(dataset_config, f)\n",
        "\n",
        "    for class_name in classes:\n",
        "        source_dir = os.path.join(dataset_path, class_name)\n",
        "        if os.path.exists(source_dir):\n",
        "            for img in os.listdir(source_dir):\n",
        "                if img.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    is_train = random.random() < 0.8\n",
        "                    subset = 'train' if is_train else 'val'\n",
        "                    img_src_path = os.path.join(source_dir, img)\n",
        "                    dest_path = os.path.join(base_dir, 'images', subset, img)\n",
        "                    shutil.copy2(img_src_path, dest_path)\n",
        "                    create_labels(img_src_path, classes[class_name], subset, base_dir)\n",
        "\n",
        "def setup_yolo():\n",
        "    from ultralytics import YOLO\n",
        "    model = YOLO('yolov8n.pt')  # Using YOLOv8 Nano for efficiency\n",
        "    return model\n",
        "\n",
        "def train_model(model, base_dir):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    print(\"Phase 1: Initial Training...\")\n",
        "    model.train(\n",
        "        data=f'{base_dir}/dataset.yaml',\n",
        "        epochs=25,\n",
        "        batch=32,\n",
        "        imgsz=640,\n",
        "        save=True,\n",
        "        project='/content/drive/MyDrive/yolo_training',\n",
        "        name='phase1_initial',\n",
        "        save_period=5,\n",
        "        device=device,\n",
        "        optimizer='AdamW',  # Optimized for GPU\n",
        "        lr0=0.01,\n",
        "        workers=8,\n",
        "        amp=True,  # Mixed Precision Training\n",
        "        cache=True,  # Speed up training\n",
        "        mosaic=0.5\n",
        "    )\n",
        "\n",
        "    print(\"\\nPhase 2: Reward Phase - Fire Engine Emphasis...\")\n",
        "    model.train(\n",
        "        data=f'{base_dir}/dataset.yaml',\n",
        "        epochs=30,\n",
        "        batch=32,\n",
        "        imgsz=640,\n",
        "        save=True,\n",
        "        project='/content/drive/MyDrive/yolo_training',\n",
        "        name='phase2_reward',\n",
        "        save_period=5,\n",
        "        device=device,\n",
        "        optimizer='AdamW',\n",
        "        lr0=0.005,\n",
        "        workers=8,\n",
        "        amp=True,\n",
        "        cache=True,\n",
        "        mosaic=0.7,\n",
        "        box=10.0,\n",
        "        cls=3.0\n",
        "    )\n",
        "\n",
        "    print(\"\\nPhase 3: Fine-tuning Fire Engine Detection...\")\n",
        "    model.train(\n",
        "        data=f'{base_dir}/dataset.yaml',\n",
        "        epochs=20,\n",
        "        batch=32,\n",
        "        imgsz=640,\n",
        "        save=True,\n",
        "        project='/content/drive/MyDrive/yolo_training',\n",
        "        name='phase3_finetune',\n",
        "        save_period=5,\n",
        "        device=device,\n",
        "        optimizer='AdamW',\n",
        "        lr0=0.001,\n",
        "        workers=8,\n",
        "        amp=True,\n",
        "        cache=True,\n",
        "        mosaic=0.3,\n",
        "        box=5.0,\n",
        "        cls=3.5\n",
        "    )\n",
        "\n",
        "def main():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    print(\"Installing dependencies...\")\n",
        "    !pip install -q ultralytics\n",
        "\n",
        "    zip_path = '/content/drive/MyDrive/Dataset.zip'\n",
        "    extract_path = '/content/Dataset'\n",
        "\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    base_dir = setup_yolo_directory()\n",
        "    organize_dataset(extract_path)\n",
        "    model = setup_yolo()\n",
        "    train_model(model, base_dir)\n",
        "    print(\"\\nTraining completed! Models saved in /content/drive/MyDrive/yolo_training/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dEdGUaZeb2r",
        "outputId": "82fbcb87-6f98-4b3f-f47a-65f5727f3d98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Installing dependencies...\n",
            "Extracting dataset...\n",
            "Dataset class distribution: {'Police': 575, 'Fire_Engine': 800, 'Ambulance': 279}\n",
            "Using device: cuda\n",
            "Phase 1: Initial Training...\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/emergency_vehicles/dataset.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=True, device=cuda, workers=4, project=/content/drive/MyDrive/yolo_training, name=phase1_initial4, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.5, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolo_training/phase1_initial4\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/yolo_training/phase1_initial4', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/emergency_vehicles/labels/train... 1377 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1378/1378 [00:00<00:00, 1572.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/emergency_vehicles/images/train/Screenshot 2024-09-23 110632.png: ignoring corrupt image/label: image size (1, 1) <10 pixels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/emergency_vehicles/labels/train.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1377/1377 [00:04<00:00, 287.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.2 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/emergency_vehicles/labels/val... 629 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 630/630 [00:00<00:00, 664.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/emergency_vehicles/images/val/Screenshot 2024-09-23 110632.png: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/emergency_vehicles/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 629/629 [00:02<00:00, 217.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/yolo_training/phase1_initial4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/yolo_training/phase1_initial4\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      2.26G      1.904      2.261       2.08          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:08<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629    0.00279      0.212    0.00224   0.000354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      2.24G      1.692      1.749      1.859          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.076      0.124     0.0425    0.00978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      2.33G      1.602      1.552      1.775          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.297       0.36      0.216     0.0642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20      2.33G      1.576      1.535      1.744          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.487      0.583      0.569       0.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      2.33G      1.434      1.383      1.624          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.566      0.719      0.583       0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20      2.32G      1.413      1.319      1.623          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.645      0.749      0.767       0.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20      2.33G      1.325      1.186      1.551          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.66      0.686      0.708      0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20      2.32G      1.337      1.199      1.593          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.756      0.825      0.851      0.682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      2.32G      1.251      1.107      1.501          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.588      0.733      0.716      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20      2.32G      1.168      1.069      1.458          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.739      0.832      0.841        0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20      2.32G     0.9213     0.8258      1.422          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.693      0.806      0.822      0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20      2.32G     0.8846     0.7567      1.403          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.707      0.908      0.896      0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      2.32G     0.8865     0.7604      1.416          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.724      0.889      0.865      0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      2.31G     0.8029     0.7129      1.335          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.857      0.836      0.896      0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20      2.32G      0.744     0.6398       1.29          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.78      0.844      0.871      0.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20      2.32G     0.7218     0.6258      1.276          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.864      0.912      0.948      0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20      2.32G     0.6906     0.5885      1.259          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.793      0.925      0.906      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      2.31G     0.6793     0.5759      1.249          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.875      0.936      0.949       0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      2.32G     0.6511     0.5615      1.235          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.912      0.935       0.97       0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      2.32G     0.6119     0.5144      1.212          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.907      0.921      0.966      0.945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.169 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/yolo_training/phase1_initial4/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/yolo_training/phase1_initial4/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/yolo_training/phase1_initial4/weights/best.pt...\n",
            "Ultralytics 8.3.70 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:07<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.906      0.921      0.966      0.945\n",
            "                Police        311        311       0.89      0.942      0.965      0.945\n",
            "           Fire_Engine        149        149      0.931       0.98      0.989      0.983\n",
            "             Ambulance        169        169      0.898       0.84      0.943      0.908\n",
            "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolo_training/phase1_initial4\u001b[0m\n",
            "\n",
            "Phase 2: Reward Phase - Fire Engine Emphasis...\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/emergency_vehicles/dataset.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=True, device=cuda, workers=4, project=/content/drive/MyDrive/yolo_training, name=phase2_reward, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=10.0, cls=3.0, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.7, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolo_training/phase2_reward\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/yolo_training/phase2_reward', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/emergency_vehicles/labels/train.cache... 1377 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1378/1378 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/emergency_vehicles/images/train/Screenshot 2024-09-23 110632.png: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1377/1377 [00:05<00:00, 244.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/emergency_vehicles/labels/val.cache... 629 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 630/630 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/emergency_vehicles/images/val/Screenshot 2024-09-23 110632.png: ignoring corrupt image/label: image size (1, 1) <10 pixels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 629/629 [00:04<00:00, 136.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/yolo_training/phase2_reward/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.005, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/yolo_training/phase2_reward\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/25      2.31G      1.594      6.312       1.47          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:28<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.74      0.712      0.821      0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/25      2.23G      1.523      5.639      1.409          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:27<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.761      0.865      0.895      0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/25      2.24G      1.523      5.642      1.397          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.786      0.831      0.886      0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/25      2.24G      1.557      5.783      1.424          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:27<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.687      0.758        0.8      0.597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/25      2.24G      1.507      5.626       1.39          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.846      0.866      0.921      0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/25      2.23G      1.501      5.486      1.373          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:27<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.746      0.833        0.9      0.682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/25      2.24G      1.446      5.208      1.367          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.887      0.895      0.955       0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/25      2.24G       1.43      5.055      1.346          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.865      0.925       0.95      0.819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/25      2.24G      1.418      5.006      1.361          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.68      0.807      0.811      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/25      2.23G      1.385      5.055      1.336          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:27<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.828      0.906      0.929      0.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/25      2.24G      1.373      4.862      1.331          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.898      0.918      0.958      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/25      2.24G      1.423      4.922      1.445          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:27<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.875      0.916       0.95      0.819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/25      2.24G      1.373      4.886      1.341          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.801      0.898      0.916      0.793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/25      2.23G      1.326      4.556        1.3          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.899       0.92      0.966       0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/25      2.24G      1.249      4.393      1.281          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.911      0.938      0.968      0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/25      2.31G      1.086      3.701      1.328          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:27<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.908      0.943      0.973      0.855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/25      2.24G      1.022      3.437      1.305          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.787      0.924      0.913      0.826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/25      2.23G     0.9619      3.178      1.279          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.949      0.949      0.981      0.901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/25      2.24G     0.9695      2.983      1.275          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.891       0.92      0.978        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/25      2.24G     0.8994      2.827      1.231          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.932      0.929      0.976       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/25      2.24G     0.9108      2.819       1.25          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.959      0.969      0.986      0.959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/25      2.23G     0.8136      2.571      1.191          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.961      0.956      0.987      0.945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/25      2.24G     0.8082      2.478      1.186          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.94      0.944      0.986      0.961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/25      2.24G     0.8249      2.406      1.209          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.942      0.951      0.987      0.955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/25      2.24G     0.8363      2.395      1.247          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.968       0.98       0.99      0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "25 epochs completed in 0.218 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/yolo_training/phase2_reward/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/yolo_training/phase2_reward/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/yolo_training/phase2_reward/weights/best.pt...\n",
            "Ultralytics 8.3.70 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.968       0.98       0.99      0.967\n",
            "                Police        311        311      0.967      0.961      0.989      0.969\n",
            "           Fire_Engine        149        149      0.998          1      0.995       0.99\n",
            "             Ambulance        169        169      0.938      0.979      0.986      0.941\n",
            "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolo_training/phase2_reward\u001b[0m\n",
            "\n",
            "Phase 3: Fine-tuning Fire Engine Detection...\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/emergency_vehicles/dataset.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=5, cache=True, device=cuda, workers=4, project=/content/drive/MyDrive/yolo_training, name=phase3_finetune, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=5.0, cls=3.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.3, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolo_training/phase3_finetune\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/yolo_training/phase3_finetune', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/emergency_vehicles/labels/train.cache... 1377 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1378/1378 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/emergency_vehicles/images/train/Screenshot 2024-09-23 110632.png: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1377/1377 [00:06<00:00, 201.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/emergency_vehicles/labels/val.cache... 629 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 630/630 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/emergency_vehicles/images/val/Screenshot 2024-09-23 110632.png: ignoring corrupt image/label: image size (1, 1) <10 pixels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 629/629 [00:03<00:00, 180.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/yolo_training/phase3_finetune/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/yolo_training/phase3_finetune\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      2.38G     0.5725      4.475      1.299          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:29<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.797      0.776      0.796      0.612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15      2.28G     0.5627      4.313      1.279          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.947      0.939       0.98      0.887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15      2.24G     0.5253      4.059      1.246          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:26<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.935      0.945      0.979      0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15      2.24G     0.5446      4.133      1.265          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.944       0.96      0.984      0.901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15      2.24G     0.5305      3.964      1.247          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.96      0.975      0.988      0.927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15      2.24G      0.435      3.072      1.225          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.957       0.96      0.987      0.943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      2.24G     0.4307      2.963      1.217          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.952      0.968      0.985      0.925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15      2.24G     0.4476      2.847      1.255          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.955      0.972       0.99      0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15      2.24G     0.4181      2.786      1.195          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.984      0.975      0.993      0.957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15      2.24G     0.3996      2.647      1.172          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.976      0.977      0.992      0.944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      2.24G     0.4128      2.855      1.198          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.985      0.979      0.993      0.957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15      2.24G     0.3984      2.535      1.184          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.993      0.968      0.993      0.949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15      2.24G     0.4009      2.525      1.188          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:24<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629       0.99      0.977      0.993       0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15      2.24G     0.4081       2.52      1.217          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:25<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.988      0.971      0.993       0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15      2.24G     0.3929      2.469      1.183          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:23<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.992      0.981      0.993      0.963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "15 epochs completed in 0.131 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/yolo_training/phase3_finetune/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/yolo_training/phase3_finetune/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/yolo_training/phase3_finetune/weights/best.pt...\n",
            "Ultralytics 8.3.70 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:07<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        629        629      0.992      0.981      0.993      0.963\n",
            "                Police        311        311      0.984       0.97      0.991      0.953\n",
            "           Fire_Engine        149        149      0.998          1      0.995      0.985\n",
            "             Ambulance        169        169      0.994      0.974      0.994      0.952\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolo_training/phase3_finetune\u001b[0m\n",
            "\n",
            "Training completed! Models saved in /content/drive/MyDrive/yolo_training/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "def mount_drive():\n",
        "    \"\"\"Mount Google Drive\"\"\"\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "def process_video(video_path, model, output_path):\n",
        "    \"\"\"Process video file for vehicle detection and save key frames\"\"\"\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Create output paths in Drive\n",
        "    output_video = str(output_path / f'{video_path.stem}_detected.mp4')\n",
        "    out = cv2.VideoWriter(output_video,\n",
        "                         cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                         fps,\n",
        "                         (frame_width, frame_height))\n",
        "\n",
        "    frames_dir = output_path / f'{video_path.stem}_frames'\n",
        "    frames_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    frame_count = 0\n",
        "    save_interval = 30\n",
        "\n",
        "    class_detections = {\n",
        "        'Police': 0,\n",
        "        'Fire_Engine': 0,\n",
        "        'Ambulance': 0\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            print(f\"\\rProcessing frame {frame_count}\", end=\"\")\n",
        "\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = model(frame_rgb, conf=0.3, iou=0.45)\n",
        "\n",
        "            for result in results:\n",
        "                for box in result.boxes:\n",
        "                    cls = int(box.cls[0])\n",
        "                    class_names = ['Police', 'Fire_Engine', 'Ambulance']\n",
        "                    class_name = class_names[cls]\n",
        "                    class_detections[class_name] += 1\n",
        "\n",
        "            detected_frame = plot_detection(frame_rgb, results)\n",
        "            detected_frame = cv2.cvtColor(detected_frame, cv2.COLOR_RGB2BGR)\n",
        "            out.write(detected_frame)\n",
        "\n",
        "            if frame_count % save_interval == 0:\n",
        "                frame_path = frames_dir / f'frame_{frame_count:04d}.jpg'\n",
        "                cv2.imwrite(str(frame_path), detected_frame)\n",
        "\n",
        "                print(f\"\\nDetections in frame {frame_count}:\")\n",
        "                for result in results:\n",
        "                    for box in result.boxes:\n",
        "                        conf = float(box.conf[0])\n",
        "                        cls = int(box.cls[0])\n",
        "                        class_names = ['Police', 'Fire_Engine', 'Ambulance']\n",
        "                        class_name = class_names[cls]\n",
        "                        print(f\"- Detected {class_name} with confidence: {conf:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing video: {e}\")\n",
        "\n",
        "    finally:\n",
        "        print(f\"\\nProcessed {frame_count} frames\")\n",
        "        print(f\"Saved detected video to {output_video}\")\n",
        "        print(f\"Saved key frames to {frames_dir}\")\n",
        "\n",
        "        print(\"\\nDetection Statistics:\")\n",
        "        for class_name, count in class_detections.items():\n",
        "            print(f\"{class_name}: {count} detections\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "def plot_detection(image, results):\n",
        "    \"\"\"Plot detection results\"\"\"\n",
        "    img = image.copy()\n",
        "    class_names = ['Police', 'Fire_Engine', 'Ambulance']\n",
        "    colors = {\n",
        "        'Police': (255, 0, 0),      # Blue\n",
        "        'Fire_Engine': (0, 165, 255), # Orange\n",
        "        'Ambulance': (0, 255, 0)    # Green\n",
        "    }\n",
        "\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = float(box.conf[0])\n",
        "            cls = int(box.cls[0])\n",
        "            class_name = class_names[cls]\n",
        "            color = colors[class_name]\n",
        "\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "            label = f'{class_name} {conf:.2f}'\n",
        "            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "            cv2.rectangle(img, (x1, y1-text_height-8), (x1+text_width, y1), color, -1)\n",
        "            cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "def process_image(img_path, model, output_path):\n",
        "    \"\"\"Process single image\"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            print(f\"Error: Could not read image {img_path}\")\n",
        "            return None\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        results = model(img, conf=0.3)\n",
        "        detected_img = plot_detection(img, results)\n",
        "\n",
        "        output_file = output_path / f'{img_path.stem}_detected.jpg'\n",
        "        plt.imsave(str(output_file), detected_img)\n",
        "\n",
        "        print(f\"\\nResults for {img_path.name}:\")\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "                class_names = ['Police', 'Fire_Engine', 'Ambulance']\n",
        "                class_name = class_names[cls]\n",
        "                print(f\"- Detected {class_name} with confidence: {conf:.2f}\")\n",
        "\n",
        "        return output_file\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {img_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    # Mount Google Drive\n",
        "    mount_drive()\n",
        "\n",
        "    # Set paths for Google Colab\n",
        "    model_path = Path('/content/drive/MyDrive/yolo_training/phase3_finetune/weights/best.pt')\n",
        "    output_path = Path('/content/drive/MyDrive/yolo_results')\n",
        "\n",
        "    # Create output directory\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if not model_path.exists():\n",
        "        print(f\"Error: Model not found at {model_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loading model from: {model_path}\")\n",
        "    model = YOLO(str(model_path))\n",
        "\n",
        "    # Process specific WhatsApp videos\n",
        "    video_files = [\n",
        "        '/content/Fire engine in Delhiï¼š Traffic on a winter morning in Delhi [Way0mXOFXk0].mp4'\n",
        "    ]\n",
        "\n",
        "    for i, video_path in enumerate(video_files, 1):\n",
        "        video_path = Path(video_path)\n",
        "        if video_path.exists():\n",
        "            print(f\"\\nProcessing video {i}/2: {video_path.name}\")\n",
        "            process_video(video_path, model, output_path)\n",
        "        else:\n",
        "            print(f\"Video not found: {video_path}\")\n",
        "\n",
        "    print(f\"\\nAll results saved to {output_path}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69KUKZu_Mkvh",
        "outputId": "4d686cfa-9728-450f-cfde-0071d53e125a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 384x640 1 Police, 19.8ms\n",
            "Speed: 3.7ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2483\n",
            "0: 384x640 1 Police, 24.7ms\n",
            "Speed: 5.6ms preprocess, 24.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2484\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 5.8ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2485\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 9.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2486\n",
            "0: 384x640 1 Police, 16.0ms\n",
            "Speed: 5.6ms preprocess, 16.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2487\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 10.5ms preprocess, 12.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2488\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 5.2ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2489\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 4.0ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2490\n",
            "0: 384x640 1 Police, 16.1ms\n",
            "Speed: 6.5ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2490:\n",
            "- Detected Police with confidence: 0.60\n",
            "Processing frame 2491\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2492\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 4.5ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2493\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2494\n",
            "0: 384x640 1 Police, 18.1ms\n",
            "Speed: 3.6ms preprocess, 18.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2495\n",
            "0: 384x640 1 Police, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2496\n",
            "0: 384x640 1 Police, 21.9ms\n",
            "Speed: 3.8ms preprocess, 21.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2497\n",
            "0: 384x640 1 Police, 14.5ms\n",
            "Speed: 4.1ms preprocess, 14.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2498\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 3.6ms preprocess, 15.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2499\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2500\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2501\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2502\n",
            "0: 384x640 1 Police, 16.9ms\n",
            "Speed: 4.0ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2503\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 3.3ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2504\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 4.5ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2505\n",
            "0: 384x640 1 Police, 16.8ms\n",
            "Speed: 3.5ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2506\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 3.5ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2507\n",
            "0: 384x640 1 Police, 15.1ms\n",
            "Speed: 6.3ms preprocess, 15.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2508\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 3.4ms preprocess, 18.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2509\n",
            "0: 384x640 1 Police, 19.4ms\n",
            "Speed: 3.4ms preprocess, 19.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2510\n",
            "0: 384x640 1 Police, 18.6ms\n",
            "Speed: 5.1ms preprocess, 18.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2511\n",
            "0: 384x640 1 Police, 17.0ms\n",
            "Speed: 4.6ms preprocess, 17.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2512\n",
            "0: 384x640 1 Police, 21.1ms\n",
            "Speed: 3.6ms preprocess, 21.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2513\n",
            "0: 384x640 1 Police, 20.7ms\n",
            "Speed: 3.7ms preprocess, 20.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2514\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 5.4ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2515\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2516\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 5.9ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2517\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2518\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2519\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 3.7ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2520\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2520:\n",
            "- Detected Police with confidence: 0.61\n",
            "Processing frame 2521\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2522\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 4.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2523\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2524\n",
            "0: 384x640 1 Police, 18.0ms\n",
            "Speed: 3.9ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2525\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 4.8ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2526\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2527\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2528\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2529\n",
            "0: 384x640 1 Police, 19.8ms\n",
            "Speed: 3.6ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2530\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2531\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 3.6ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2532\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2533\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2534\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2535\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 7.5ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2536\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2537\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 4.0ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2538\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 5.6ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2539\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 3.4ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2540\n",
            "0: 384x640 1 Police, 12.7ms\n",
            "Speed: 5.3ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2541\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 3.8ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2542\n",
            "0: 384x640 1 Police, 15.4ms\n",
            "Speed: 3.5ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2543\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 4.6ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2544\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2545\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 4.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2546\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 4.2ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2547\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2548\n",
            "0: 384x640 1 Police, 9.2ms\n",
            "Speed: 4.9ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2549\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2550\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2550:\n",
            "- Detected Police with confidence: 0.68\n",
            "Processing frame 2551\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2552\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2553\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 4.6ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2554\n",
            "0: 384x640 1 Police, 16.0ms\n",
            "Speed: 5.7ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2555\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 7.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2556\n",
            "0: 384x640 1 Police, 19.5ms\n",
            "Speed: 4.4ms preprocess, 19.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2557\n",
            "0: 384x640 1 Police, 20.6ms\n",
            "Speed: 4.0ms preprocess, 20.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2558\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 5.7ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2559\n",
            "0: 384x640 1 Police, 17.5ms\n",
            "Speed: 3.9ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2560\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2561\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2562\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2563\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 4.0ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2564\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2565\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2566\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2567\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 7.6ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2568\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2569\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2570\n",
            "0: 384x640 1 Police, 17.7ms\n",
            "Speed: 5.6ms preprocess, 17.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2571\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2572\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 7.3ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2573\n",
            "0: 384x640 1 Police, 9.2ms\n",
            "Speed: 5.2ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2574\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2575\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2576\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 5.5ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2577\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 5.2ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2578\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2579\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 5.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2580\n",
            "0: 384x640 1 Police, 8.5ms\n",
            "Speed: 6.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2580:\n",
            "- Detected Police with confidence: 0.72\n",
            "Processing frame 2581\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 4.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2582\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 4.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2583\n",
            "0: 384x640 1 Police, 17.9ms\n",
            "Speed: 5.2ms preprocess, 17.9ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2584\n",
            "0: 384x640 1 Police, 13.9ms\n",
            "Speed: 8.2ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2585\n",
            "0: 384x640 1 Police, 14.0ms\n",
            "Speed: 7.2ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2586\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 8.2ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2587\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 8.2ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2588\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2589\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2590\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2591\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 3.8ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2592\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 4.5ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2593\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 6.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2594\n",
            "0: 384x640 1 Police, 9.2ms\n",
            "Speed: 6.4ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2595\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2596\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 5.6ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2597\n",
            "0: 384x640 1 Police, 19.8ms\n",
            "Speed: 3.5ms preprocess, 19.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2598\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 5.8ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2599\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 6.0ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2600\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 11.7ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2601\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 4.2ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2602\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2603\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2604\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 6.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2605\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2606\n",
            "0: 384x640 1 Police, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2607\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2608\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2609\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2610\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2610:\n",
            "- Detected Police with confidence: 0.77\n",
            "Processing frame 2611\n",
            "0: 384x640 1 Police, 12.7ms\n",
            "Speed: 4.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2612\n",
            "0: 384x640 1 Police, 19.3ms\n",
            "Speed: 3.8ms preprocess, 19.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2613\n",
            "0: 384x640 1 Police, 1 Ambulance, 8.6ms\n",
            "Speed: 5.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2614\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2615\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2616\n",
            "0: 384x640 1 Police, 1 Ambulance, 8.7ms\n",
            "Speed: 5.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2617\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 5.1ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2618\n",
            "0: 384x640 1 Police, 1 Ambulance, 8.8ms\n",
            "Speed: 6.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2619\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2620\n",
            "0: 384x640 1 Police, 13.5ms\n",
            "Speed: 6.9ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2621\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2622\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2623\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2624\n",
            "0: 384x640 1 Ambulance, 20.7ms\n",
            "Speed: 12.0ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2625\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 13.6ms preprocess, 12.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2626\n",
            "0: 384x640 1 Police, 12.7ms\n",
            "Speed: 4.9ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2627\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2628\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 5.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2629\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 3.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2630\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 4.6ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2631\n",
            "0: 384x640 1 Ambulance, 15.0ms\n",
            "Speed: 6.4ms preprocess, 15.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2632\n",
            "0: 384x640 1 Ambulance, 19.0ms\n",
            "Speed: 3.6ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2633\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2634\n",
            "0: 384x640 1 Ambulance, 14.5ms\n",
            "Speed: 3.9ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2635\n",
            "0: 384x640 1 Ambulance, 20.9ms\n",
            "Speed: 3.6ms preprocess, 20.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2636\n",
            "0: 384x640 1 Ambulance, 9.1ms\n",
            "Speed: 3.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2637\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2638\n",
            "0: 384x640 1 Ambulance, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2639\n",
            "0: 384x640 1 Ambulance, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2640\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 5.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2640:\n",
            "- Detected Ambulance with confidence: 0.64\n",
            "Processing frame 2641\n",
            "0: 384x640 1 Ambulance, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2642\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2643\n",
            "0: 384x640 1 Ambulance, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2644\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 10.9ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2645\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2646\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.6ms\n",
            "Speed: 5.0ms preprocess, 11.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2647\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2648\n",
            "0: 384x640 1 Ambulance, 8.6ms\n",
            "Speed: 6.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2649\n",
            "0: 384x640 1 Ambulance, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2650\n",
            "0: 384x640 1 Ambulance, 9.5ms\n",
            "Speed: 8.9ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2651\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2652\n",
            "0: 384x640 1 Ambulance, 23.9ms\n",
            "Speed: 4.8ms preprocess, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2653\n",
            "0: 384x640 1 Ambulance, 12.9ms\n",
            "Speed: 6.4ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2654\n",
            "0: 384x640 1 Ambulance, 15.6ms\n",
            "Speed: 4.1ms preprocess, 15.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2655\n",
            "0: 384x640 1 Ambulance, 11.8ms\n",
            "Speed: 5.1ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2656\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2657\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2658\n",
            "0: 384x640 1 Ambulance, 12.7ms\n",
            "Speed: 4.8ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2659\n",
            "0: 384x640 1 Ambulance, 16.9ms\n",
            "Speed: 3.5ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2660\n",
            "0: 384x640 1 Ambulance, 14.1ms\n",
            "Speed: 3.6ms preprocess, 14.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2661\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 4.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2662\n",
            "0: 384x640 1 Ambulance, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2663\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 4.7ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2664\n",
            "0: 384x640 1 Ambulance, 13.2ms\n",
            "Speed: 8.1ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2665\n",
            "0: 384x640 1 Ambulance, 18.4ms\n",
            "Speed: 4.8ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2666\n",
            "0: 384x640 1 Ambulance, 18.9ms\n",
            "Speed: 3.6ms preprocess, 18.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2667\n",
            "0: 384x640 1 Ambulance, 12.4ms\n",
            "Speed: 8.7ms preprocess, 12.4ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2668\n",
            "0: 384x640 1 Ambulance, 23.8ms\n",
            "Speed: 4.7ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2669\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 3.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2670\n",
            "0: 384x640 1 Ambulance, 12.3ms\n",
            "Speed: 3.6ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2670:\n",
            "- Detected Ambulance with confidence: 0.77\n",
            "Processing frame 2671\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2672\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 4.7ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2673\n",
            "0: 384x640 1 Ambulance, 24.4ms\n",
            "Speed: 4.7ms preprocess, 24.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2674\n",
            "0: 384x640 1 Ambulance, 16.2ms\n",
            "Speed: 7.5ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2675\n",
            "0: 384x640 1 Ambulance, 13.9ms\n",
            "Speed: 5.1ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2676\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 5.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2677\n",
            "0: 384x640 1 Ambulance, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2678\n",
            "0: 384x640 1 Ambulance, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2679\n",
            "0: 384x640 1 Ambulance, 17.4ms\n",
            "Speed: 6.0ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2680\n",
            "0: 384x640 1 Ambulance, 17.1ms\n",
            "Speed: 6.9ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2681\n",
            "0: 384x640 1 Ambulance, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2682\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2683\n",
            "0: 384x640 1 Ambulance, 14.8ms\n",
            "Speed: 3.4ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2684\n",
            "0: 384x640 1 Ambulance, 16.8ms\n",
            "Speed: 3.5ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2685\n",
            "0: 384x640 1 Ambulance, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2686\n",
            "0: 384x640 1 Ambulance, 17.2ms\n",
            "Speed: 5.8ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2687\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 4.9ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2688\n",
            "0: 384x640 1 Ambulance, 18.1ms\n",
            "Speed: 5.5ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2689\n",
            "0: 384x640 1 Ambulance, 17.0ms\n",
            "Speed: 3.6ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2690\n",
            "0: 384x640 1 Ambulance, 13.9ms\n",
            "Speed: 4.9ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2691\n",
            "0: 384x640 1 Ambulance, 20.6ms\n",
            "Speed: 3.7ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2692\n",
            "0: 384x640 1 Ambulance, 23.1ms\n",
            "Speed: 4.2ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2693\n",
            "0: 384x640 1 Ambulance, 20.8ms\n",
            "Speed: 3.6ms preprocess, 20.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2694\n",
            "0: 384x640 1 Ambulance, 11.8ms\n",
            "Speed: 5.5ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2695\n",
            "0: 384x640 1 Ambulance, 26.5ms\n",
            "Speed: 6.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2696\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 5.5ms preprocess, 10.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2697\n",
            "0: 384x640 1 Ambulance, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2698\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2699\n",
            "0: 384x640 1 Ambulance, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2700\n",
            "0: 384x640 1 Ambulance, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2700:\n",
            "- Detected Ambulance with confidence: 0.72\n",
            "Processing frame 2701\n",
            "0: 384x640 1 Ambulance, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2702\n",
            "0: 384x640 1 Ambulance, 15.5ms\n",
            "Speed: 6.0ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2703\n",
            "0: 384x640 1 Ambulance, 13.2ms\n",
            "Speed: 5.1ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2704\n",
            "0: 384x640 1 Ambulance, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2705\n",
            "0: 384x640 1 Ambulance, 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2706\n",
            "0: 384x640 1 Ambulance, 14.9ms\n",
            "Speed: 3.4ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2707\n",
            "0: 384x640 1 Ambulance, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2708\n",
            "0: 384x640 1 Ambulance, 17.2ms\n",
            "Speed: 3.5ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2709\n",
            "0: 384x640 1 Ambulance, 13.7ms\n",
            "Speed: 3.5ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2710\n",
            "0: 384x640 1 Ambulance, 12.7ms\n",
            "Speed: 4.7ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2711\n",
            "0: 384x640 1 Ambulance, 20.1ms\n",
            "Speed: 3.5ms preprocess, 20.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2712\n",
            "0: 384x640 1 Ambulance, 16.7ms\n",
            "Speed: 4.7ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2713\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.4ms\n",
            "Speed: 4.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2714\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.8ms\n",
            "Speed: 4.2ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2715\n",
            "0: 384x640 1 Ambulance, 17.0ms\n",
            "Speed: 6.5ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2716\n",
            "0: 384x640 1 Ambulance, 16.3ms\n",
            "Speed: 3.5ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2717\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 4.3ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2718\n",
            "0: 384x640 1 Ambulance, 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2719\n",
            "0: 384x640 1 Ambulance, 14.2ms\n",
            "Speed: 3.7ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2720\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 4.7ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2721\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2722\n",
            "0: 384x640 1 Ambulance, 12.9ms\n",
            "Speed: 3.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2723\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 4.2ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2724\n",
            "0: 384x640 1 Ambulance, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2725\n",
            "0: 384x640 1 Ambulance, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2726\n",
            "0: 384x640 1 Ambulance, 23.3ms\n",
            "Speed: 3.5ms preprocess, 23.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2727\n",
            "0: 384x640 1 Ambulance, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2728\n",
            "0: 384x640 1 Ambulance, 15.4ms\n",
            "Speed: 8.8ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2729\n",
            "0: 384x640 1 Ambulance, 16.0ms\n",
            "Speed: 3.7ms preprocess, 16.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2730\n",
            "0: 384x640 1 Ambulance, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2730:\n",
            "- Detected Ambulance with confidence: 0.74\n",
            "Processing frame 2731\n",
            "0: 384x640 1 Ambulance, 18.4ms\n",
            "Speed: 6.1ms preprocess, 18.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2732\n",
            "0: 384x640 1 Ambulance, 15.8ms\n",
            "Speed: 4.5ms preprocess, 15.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2733\n",
            "0: 384x640 1 Ambulance, 14.3ms\n",
            "Speed: 4.8ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2734\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 9.6ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2735\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 3.7ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2736\n",
            "0: 384x640 1 Ambulance, 9.3ms\n",
            "Speed: 4.9ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2737\n",
            "0: 384x640 1 Ambulance, 10.6ms\n",
            "Speed: 4.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2738\n",
            "0: 384x640 1 Ambulance, 13.7ms\n",
            "Speed: 6.5ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2739\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.5ms\n",
            "Speed: 3.6ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2740\n",
            "0: 384x640 1 Ambulance, 12.0ms\n",
            "Speed: 6.5ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2741\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.3ms\n",
            "Speed: 4.6ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2742\n",
            "0: 384x640 1 Ambulance, 14.8ms\n",
            "Speed: 6.1ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2743\n",
            "0: 384x640 1 Ambulance, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2744\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2745\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2746\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.9ms\n",
            "Speed: 3.7ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2747\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2748\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.8ms\n",
            "Speed: 8.1ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2749\n",
            "0: 384x640 1 Ambulance, 18.8ms\n",
            "Speed: 3.7ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2750\n",
            "0: 384x640 1 Ambulance, 17.8ms\n",
            "Speed: 3.6ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2751\n",
            "0: 384x640 1 Ambulance, 12.5ms\n",
            "Speed: 3.6ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2752\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2753\n",
            "0: 384x640 1 Ambulance, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2754\n",
            "0: 384x640 1 Ambulance, 16.2ms\n",
            "Speed: 6.0ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2755\n",
            "0: 384x640 1 Ambulance, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2756\n",
            "0: 384x640 1 Ambulance, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2757\n",
            "0: 384x640 1 Ambulance, 12.6ms\n",
            "Speed: 3.6ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2758\n",
            "0: 384x640 1 Ambulance, 14.1ms\n",
            "Speed: 4.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2759\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2760\n",
            "0: 384x640 1 Ambulance, 26.7ms\n",
            "Speed: 24.9ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2760:\n",
            "- Detected Ambulance with confidence: 0.72\n",
            "Processing frame 2761\n",
            "0: 384x640 1 Ambulance, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2762\n",
            "0: 384x640 1 Ambulance, 13.2ms\n",
            "Speed: 3.5ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2763\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2764\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 8.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2765\n",
            "0: 384x640 1 Ambulance, 10.1ms\n",
            "Speed: 5.2ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2766\n",
            "0: 384x640 1 Ambulance, 11.9ms\n",
            "Speed: 4.3ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2767\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 5.2ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2768\n",
            "0: 384x640 1 Ambulance, 12.0ms\n",
            "Speed: 4.7ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2769\n",
            "0: 384x640 1 Ambulance, 17.8ms\n",
            "Speed: 6.6ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2770\n",
            "0: 384x640 1 Ambulance, 10.4ms\n",
            "Speed: 5.7ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2771\n",
            "0: 384x640 1 Ambulance, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2772\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 3.7ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2773\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 6.5ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2774\n",
            "0: 384x640 1 Ambulance, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2775\n",
            "0: 384x640 1 Ambulance, 15.8ms\n",
            "Speed: 7.2ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2776\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 4.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2777\n",
            "0: 384x640 1 Ambulance, 12.0ms\n",
            "Speed: 5.6ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2778\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 6.0ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2779\n",
            "0: 384x640 1 Ambulance, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2780\n",
            "0: 384x640 1 Ambulance, 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2781\n",
            "0: 384x640 1 Ambulance, 16.4ms\n",
            "Speed: 3.6ms preprocess, 16.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2782\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 6.8ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2783\n",
            "0: 384x640 1 Ambulance, 9.3ms\n",
            "Speed: 4.5ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2784\n",
            "0: 384x640 1 Ambulance, 12.1ms\n",
            "Speed: 4.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2785\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 6.9ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2786\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.5ms\n",
            "Speed: 4.4ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2787\n",
            "0: 384x640 1 Ambulance, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2788\n",
            "0: 384x640 1 Ambulance, 11.8ms\n",
            "Speed: 6.5ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2789\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 4.9ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2790\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 6.0ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2790:\n",
            "- Detected Police with confidence: 0.40\n",
            "Processing frame 2791\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2792\n",
            "0: 384x640 1 Police, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2793\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 8.9ms preprocess, 12.4ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2794\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.2ms\n",
            "Speed: 8.9ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2795\n",
            "0: 384x640 1 Police, 14.5ms\n",
            "Speed: 6.8ms preprocess, 14.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2796\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 5.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2797\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2798\n",
            "0: 384x640 1 Police, 12.1ms\n",
            "Speed: 3.8ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2799\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 6.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2800\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 4.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2801\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 10.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2802\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2803\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 5.0ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2804\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2805\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2806\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 6.5ms preprocess, 15.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2807\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2808\n",
            "0: 384x640 1 Police, 13.5ms\n",
            "Speed: 6.6ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2809\n",
            "0: 384x640 1 Police, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2810\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2811\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2812\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2813\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.9ms\n",
            "Speed: 6.9ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2814\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.8ms\n",
            "Speed: 7.6ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2815\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2816\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2817\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.9ms\n",
            "Speed: 5.4ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2818\n",
            "0: 384x640 1 Police, 23.2ms\n",
            "Speed: 3.7ms preprocess, 23.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2819\n",
            "0: 384x640 1 Police, 21.9ms\n",
            "Speed: 8.1ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2820\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 3.7ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2820:\n",
            "- Detected Police with confidence: 0.49\n",
            "Processing frame 2821\n",
            "0: 384x640 1 Police, 15.1ms\n",
            "Speed: 12.2ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2822\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2823\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2824\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2825\n",
            "0: 384x640 1 Police, 17.9ms\n",
            "Speed: 3.5ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2826\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 5.4ms preprocess, 15.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2827\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 3.5ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2828\n",
            "0: 384x640 1 Police, 22.1ms\n",
            "Speed: 3.6ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2829\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 6.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2830\n",
            "0: 384x640 1 Police, 20.5ms\n",
            "Speed: 3.6ms preprocess, 20.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2831\n",
            "0: 384x640 1 Police, 21.5ms\n",
            "Speed: 6.3ms preprocess, 21.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2832\n",
            "0: 384x640 1 Police, 25.5ms\n",
            "Speed: 3.6ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2833\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 4.6ms preprocess, 14.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2834\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2835\n",
            "0: 384x640 1 Police, 17.7ms\n",
            "Speed: 14.3ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2836\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2837\n",
            "0: 384x640 1 Police, 16.9ms\n",
            "Speed: 3.7ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2838\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2839\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 4.1ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2840\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2841\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 3.5ms preprocess, 18.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2842\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 8.7ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2843\n",
            "0: 384x640 (no detections), 30.0ms\n",
            "Speed: 3.7ms preprocess, 30.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2844\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.7ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2845\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 8.3ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2846\n",
            "0: 384x640 1 Police, 14.0ms\n",
            "Speed: 6.8ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2847\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2848\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 4.4ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2849\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2850\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 5.3ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2850:\n",
            "- Detected Police with confidence: 0.36\n",
            "Processing frame 2851\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2852\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2853\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2854\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 4.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2855\n",
            "0: 384x640 1 Police, 16.6ms\n",
            "Speed: 7.1ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2856\n",
            "0: 384x640 1 Police, 19.5ms\n",
            "Speed: 3.6ms preprocess, 19.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2857\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 5.9ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2858\n",
            "0: 384x640 1 Police, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2859\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 7.1ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2860\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 7.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2861\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2862\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 4.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2863\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2864\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 3.9ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2865\n",
            "0: 384x640 1 Police, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2866\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 5.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2867\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 6.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2868\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 5.4ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2869\n",
            "0: 384x640 1 Police, 18.0ms\n",
            "Speed: 10.9ms preprocess, 18.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2870\n",
            "0: 384x640 1 Police, 19.3ms\n",
            "Speed: 6.5ms preprocess, 19.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2871\n",
            "0: 384x640 1 Police, 9.1ms\n",
            "Speed: 8.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2872\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2873\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 5.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2874\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 17.4ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2875\n",
            "0: 384x640 1 Police, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2876\n",
            "0: 384x640 1 Police, 8.4ms\n",
            "Speed: 3.9ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2877\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 7.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2878\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2879\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2880\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2880:\n",
            "- Detected Police with confidence: 0.45\n",
            "Processing frame 2881\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 6.5ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2882\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2883\n",
            "0: 384x640 1 Police, 14.9ms\n",
            "Speed: 7.9ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2884\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2885\n",
            "0: 384x640 1 Police, 12.1ms\n",
            "Speed: 3.8ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2886\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2887\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 4.1ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2888\n",
            "0: 384x640 1 Police, 14.9ms\n",
            "Speed: 6.2ms preprocess, 14.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2889\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2890\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 5.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2891\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2892\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 5.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2893\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 5.8ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2894\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.3ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2895\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 5.0ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2896\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 4.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2897\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2898\n",
            "0: 384x640 1 Police, 13.1ms\n",
            "Speed: 9.5ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2899\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2900\n",
            "0: 384x640 1 Police, 18.5ms\n",
            "Speed: 3.8ms preprocess, 18.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2901\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 4.1ms preprocess, 11.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2902\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2903\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 5.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2904\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 8.6ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2905\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 4.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2906\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2907\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 4.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2908\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2909\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 4.7ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2910\n",
            "0: 384x640 1 Police, 11.6ms\n",
            "Speed: 3.5ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2910:\n",
            "- Detected Police with confidence: 0.55\n",
            "Processing frame 2911\n",
            "0: 384x640 1 Police, 20.5ms\n",
            "Speed: 8.5ms preprocess, 20.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2912\n",
            "0: 384x640 1 Police, 17.8ms\n",
            "Speed: 5.7ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2913\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 9.2ms preprocess, 15.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2914\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2915\n",
            "0: 384x640 1 Police, 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2916\n",
            "0: 384x640 1 Police, 21.6ms\n",
            "Speed: 4.1ms preprocess, 21.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2917\n",
            "0: 384x640 1 Police, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2918\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2919\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.9ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2920\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2921\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 4.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2922\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2923\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 4.5ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2924\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2925\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2926\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2927\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 10.3ms preprocess, 17.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2928\n",
            "0: 384x640 1 Police, 16.1ms\n",
            "Speed: 5.7ms preprocess, 16.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2929\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 6.8ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2930\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 5.0ms preprocess, 10.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2931\n",
            "0: 384x640 1 Police, 16.4ms\n",
            "Speed: 6.4ms preprocess, 16.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2932\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2933\n",
            "0: 384x640 1 Police, 29.0ms\n",
            "Speed: 3.7ms preprocess, 29.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2934\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2935\n",
            "0: 384x640 1 Police, 20.7ms\n",
            "Speed: 3.3ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2936\n",
            "0: 384x640 1 Police, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2937\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2938\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2939\n",
            "0: 384x640 1 Police, 16.8ms\n",
            "Speed: 3.5ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2940\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2940:\n",
            "- Detected Police with confidence: 0.51\n",
            "Processing frame 2941\n",
            "0: 384x640 1 Police, 17.9ms\n",
            "Speed: 5.7ms preprocess, 17.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2942\n",
            "0: 384x640 1 Police, 33.0ms\n",
            "Speed: 12.9ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2943\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2944\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2945\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2946\n",
            "0: 384x640 1 Police, 14.6ms\n",
            "Speed: 3.7ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2947\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2948\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 4.8ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2949\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 4.4ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2950\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 8.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2951\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 4.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2952\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 4.7ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2953\n",
            "0: 384x640 1 Police, 15.4ms\n",
            "Speed: 5.7ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2954\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2955\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 4.6ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2956\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2957\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 5.9ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2958\n",
            "0: 384x640 1 Police, 24.8ms\n",
            "Speed: 7.2ms preprocess, 24.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2959\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 7.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2960\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2961\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2962\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2963\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2964\n",
            "0: 384x640 1 Police, 13.6ms\n",
            "Speed: 3.5ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2965\n",
            "0: 384x640 1 Police, 8.5ms\n",
            "Speed: 3.9ms preprocess, 8.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2966\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 7.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2967\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2968\n",
            "0: 384x640 1 Police, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2969\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 4.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2970\n",
            "0: 384x640 1 Police, 9.1ms\n",
            "Speed: 4.9ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 2970:\n",
            "- Detected Police with confidence: 0.63\n",
            "Processing frame 2971\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 4.9ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2972\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 5.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2973\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2974\n",
            "0: 384x640 1 Police, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2975\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 4.6ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2976\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 3.6ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2977\n",
            "0: 384x640 1 Police, 12.3ms\n",
            "Speed: 4.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2978\n",
            "0: 384x640 1 Police, 17.1ms\n",
            "Speed: 4.1ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2979\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2980\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2981\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2982\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 4.6ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2983\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2984\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2985\n",
            "0: 384x640 1 Police, 15.2ms\n",
            "Speed: 4.0ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2986\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 3.5ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2987\n",
            "0: 384x640 1 Police, 15.0ms\n",
            "Speed: 6.6ms preprocess, 15.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2988\n",
            "0: 384x640 1 Police, 14.2ms\n",
            "Speed: 9.6ms preprocess, 14.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2989\n",
            "0: 384x640 1 Police, 9.2ms\n",
            "Speed: 5.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2990\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 3.7ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2991\n",
            "0: 384x640 1 Police, 17.2ms\n",
            "Speed: 3.6ms preprocess, 17.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2992\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.5ms\n",
            "Speed: 3.4ms preprocess, 13.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2993\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 5.5ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2994\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2995\n",
            "0: 384x640 1 Police, 16.1ms\n",
            "Speed: 3.3ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2996\n",
            "0: 384x640 1 Police, 19.3ms\n",
            "Speed: 6.3ms preprocess, 19.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2997\n",
            "0: 384x640 1 Police, 14.5ms\n",
            "Speed: 4.5ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2998\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2999\n",
            "0: 384x640 1 Police, 13.2ms\n",
            "Speed: 4.9ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3000\n",
            "0: 384x640 1 Police, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3000:\n",
            "- Detected Police with confidence: 0.61\n",
            "Processing frame 3001\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 9.6ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3002\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 7.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3003\n",
            "0: 384x640 1 Police, 18.8ms\n",
            "Speed: 3.6ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3004\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 6.8ms preprocess, 15.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3005\n",
            "0: 384x640 1 Police, 16.6ms\n",
            "Speed: 3.7ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3006\n",
            "0: 384x640 1 Police, 18.2ms\n",
            "Speed: 3.6ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3007\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 3.6ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3008\n",
            "0: 384x640 1 Police, 14.6ms\n",
            "Speed: 3.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3009\n",
            "0: 384x640 1 Police, 17.9ms\n",
            "Speed: 3.7ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3010\n",
            "0: 384x640 1 Police, 19.5ms\n",
            "Speed: 3.7ms preprocess, 19.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3011\n",
            "0: 384x640 1 Police, 23.9ms\n",
            "Speed: 3.7ms preprocess, 23.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3012\n",
            "0: 384x640 1 Police, 53.8ms\n",
            "Speed: 4.6ms preprocess, 53.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3013\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3014\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 3.6ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3015\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 4.5ms preprocess, 15.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3016\n",
            "0: 384x640 1 Police, 12.3ms\n",
            "Speed: 4.3ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3017\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 4.8ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3018\n",
            "0: 384x640 1 Police, 16.8ms\n",
            "Speed: 4.6ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3019\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.2ms\n",
            "Speed: 5.2ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3020\n",
            "0: 384x640 1 Police, 16.0ms\n",
            "Speed: 3.5ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3021\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3022\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.4ms\n",
            "Speed: 3.3ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3023\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.1ms\n",
            "Speed: 4.6ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3024\n",
            "0: 384x640 1 Police, 1 Ambulance, 21.5ms\n",
            "Speed: 3.6ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3025\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.3ms\n",
            "Speed: 17.2ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3026\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3027\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.4ms\n",
            "Speed: 5.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3028\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.1ms\n",
            "Speed: 6.3ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3029\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.6ms\n",
            "Speed: 3.5ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3030\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3030:\n",
            "- Detected Ambulance with confidence: 0.57\n",
            "- Detected Police with confidence: 0.45\n",
            "Processing frame 3031\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.2ms\n",
            "Speed: 3.5ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3032\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3033\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.1ms\n",
            "Speed: 10.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3034\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.9ms\n",
            "Speed: 4.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3035\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3036\n",
            "0: 384x640 1 Police, 1 Ambulance, 24.4ms\n",
            "Speed: 3.6ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3037\n",
            "0: 384x640 1 Police, 1 Ambulance, 21.4ms\n",
            "Speed: 4.8ms preprocess, 21.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3038\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.6ms\n",
            "Speed: 3.4ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3039\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.6ms\n",
            "Speed: 4.7ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3040\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3041\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.0ms\n",
            "Speed: 8.1ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3042\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.8ms\n",
            "Speed: 5.6ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3043\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3044\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.3ms\n",
            "Speed: 3.6ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3045\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.0ms\n",
            "Speed: 3.5ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3046\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3047\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.7ms\n",
            "Speed: 4.7ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3048\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.4ms\n",
            "Speed: 4.2ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3049\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3050\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3051\n",
            "0: 384x640 1 Police, 1 Ambulance, 32.2ms\n",
            "Speed: 4.5ms preprocess, 32.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3052\n",
            "0: 384x640 1 Police, 1 Ambulance, 20.3ms\n",
            "Speed: 6.4ms preprocess, 20.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3053\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3054\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3055\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.5ms\n",
            "Speed: 5.4ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3056\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.6ms\n",
            "Speed: 5.0ms preprocess, 13.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3057\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.6ms\n",
            "Speed: 7.1ms preprocess, 9.6ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3058\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.7ms\n",
            "Speed: 5.5ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3059\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.7ms\n",
            "Speed: 3.9ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3060\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3060:\n",
            "- Detected Police with confidence: 0.50\n",
            "- Detected Ambulance with confidence: 0.43\n",
            "Processing frame 3061\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.4ms\n",
            "Speed: 3.5ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3062\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.2ms\n",
            "Speed: 3.6ms preprocess, 19.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3063\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.4ms\n",
            "Speed: 3.6ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3064\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.4ms\n",
            "Speed: 9.4ms preprocess, 17.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3065\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.3ms\n",
            "Speed: 8.5ms preprocess, 19.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3066\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.4ms\n",
            "Speed: 4.0ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3067\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3068\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3069\n",
            "0: 384x640 1 Police, 1 Ambulance, 20.8ms\n",
            "Speed: 5.5ms preprocess, 20.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3070\n",
            "0: 384x640 1 Police, 1 Ambulance, 21.5ms\n",
            "Speed: 3.5ms preprocess, 21.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3071\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3072\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.5ms\n",
            "Speed: 4.6ms preprocess, 16.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3073\n",
            "0: 384x640 1 Ambulance, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3074\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.2ms\n",
            "Speed: 3.6ms preprocess, 19.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3075\n",
            "0: 384x640 1 Ambulance, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3076\n",
            "0: 384x640 1 Police, 1 Ambulance, 24.9ms\n",
            "Speed: 3.6ms preprocess, 24.9ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3077\n",
            "0: 384x640 1 Police, 1 Ambulance, 20.1ms\n",
            "Speed: 3.6ms preprocess, 20.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3078\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.8ms\n",
            "Speed: 6.7ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3079\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.8ms\n",
            "Speed: 7.2ms preprocess, 12.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3080\n",
            "0: 384x640 1 Police, 17.5ms\n",
            "Speed: 3.5ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3081\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.7ms\n",
            "Speed: 4.2ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3082\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.1ms\n",
            "Speed: 4.4ms preprocess, 18.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3083\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3084\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.1ms\n",
            "Speed: 3.5ms preprocess, 15.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3085\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3086\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3087\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.4ms\n",
            "Speed: 3.5ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3088\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3089\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.5ms\n",
            "Speed: 3.5ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3090\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.1ms\n",
            "Speed: 3.6ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3090:\n",
            "- Detected Police with confidence: 0.57\n",
            "- Detected Ambulance with confidence: 0.35\n",
            "Processing frame 3091\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.7ms\n",
            "Speed: 5.6ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3092\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.5ms\n",
            "Speed: 3.5ms preprocess, 16.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3093\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.5ms\n",
            "Speed: 3.5ms preprocess, 14.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3094\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3095\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3096\n",
            "0: 384x640 1 Police, 1 Ambulance, 22.8ms\n",
            "Speed: 4.5ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3097\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3098\n",
            "0: 384x640 1 Police, 1 Ambulance, 21.7ms\n",
            "Speed: 3.5ms preprocess, 21.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3099\n",
            "0: 384x640 1 Police, 1 Ambulance, 22.6ms\n",
            "Speed: 3.5ms preprocess, 22.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3100\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3101\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.4ms\n",
            "Speed: 5.6ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3102\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3103\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.4ms\n",
            "Speed: 4.0ms preprocess, 13.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3104\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3105\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.8ms\n",
            "Speed: 4.9ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3106\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.8ms\n",
            "Speed: 3.4ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3107\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3108\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.1ms\n",
            "Speed: 4.7ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3109\n",
            "0: 384x640 1 Police, 1 Ambulance, 8.6ms\n",
            "Speed: 5.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3110\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 4.5ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3111\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3112\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3113\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3114\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.1ms\n",
            "Speed: 3.5ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3115\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3116\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.1ms\n",
            "Speed: 3.5ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3117\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3118\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3119\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3120\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3120:\n",
            "- Detected Ambulance with confidence: 0.54\n",
            "- Detected Police with confidence: 0.44\n",
            "Processing frame 3121\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.0ms\n",
            "Speed: 5.1ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3122\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.4ms\n",
            "Speed: 5.4ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3123\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3124\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3125\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.9ms\n",
            "Speed: 7.5ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3126\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.2ms\n",
            "Speed: 8.5ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3127\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3128\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.2ms\n",
            "Speed: 3.5ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3129\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.4ms\n",
            "Speed: 4.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3130\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.2ms\n",
            "Speed: 4.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3131\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.0ms\n",
            "Speed: 3.6ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3132\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3133\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3134\n",
            "0: 384x640 1 Police, 1 Ambulance, 26.2ms\n",
            "Speed: 3.7ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3135\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.8ms\n",
            "Speed: 3.6ms preprocess, 13.8ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3136\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.5ms\n",
            "Speed: 3.5ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3137\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.7ms\n",
            "Speed: 3.5ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3138\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3139\n",
            "0: 384x640 1 Ambulance, 14.7ms\n",
            "Speed: 3.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3140\n",
            "0: 384x640 1 Ambulance, 16.6ms\n",
            "Speed: 3.6ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3141\n",
            "0: 384x640 1 Ambulance, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3142\n",
            "0: 384x640 1 Ambulance, 20.9ms\n",
            "Speed: 6.8ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3143\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3144\n",
            "0: 384x640 1 Police, 1 Ambulance, 20.6ms\n",
            "Speed: 4.7ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3145\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3146\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 3.6ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3147\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 3.5ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3148\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.9ms\n",
            "Speed: 3.5ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3149\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3150\n",
            "0: 384x640 1 Ambulance, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3150:\n",
            "- Detected Ambulance with confidence: 0.55\n",
            "Processing frame 3151\n",
            "0: 384x640 1 Ambulance, 13.3ms\n",
            "Speed: 3.6ms preprocess, 13.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3152\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3153\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3154\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.6ms\n",
            "Speed: 6.1ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3155\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3156\n",
            "0: 384x640 1 Ambulance, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3157\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3158\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.6ms\n",
            "Speed: 3.6ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3159\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 3.3ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3160\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.8ms\n",
            "Speed: 6.5ms preprocess, 13.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3161\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.0ms\n",
            "Speed: 12.5ms preprocess, 19.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3162\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.1ms\n",
            "Speed: 3.9ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3163\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3164\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3165\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3166\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3167\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.1ms\n",
            "Speed: 3.3ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3168\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3169\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3170\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.9ms\n",
            "Speed: 3.6ms preprocess, 12.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3171\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3172\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3173\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3174\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.1ms\n",
            "Speed: 3.4ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3175\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.0ms\n",
            "Speed: 3.4ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3176\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.1ms\n",
            "Speed: 3.6ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3177\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3178\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.2ms\n",
            "Speed: 6.6ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3179\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3180\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3180:\n",
            "- Detected Police with confidence: 0.56\n",
            "- Detected Ambulance with confidence: 0.37\n",
            "Processing frame 3181\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.1ms\n",
            "Speed: 8.5ms preprocess, 16.1ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3182\n",
            "0: 384x640 1 Police, 1 Ambulance, 19.0ms\n",
            "Speed: 3.6ms preprocess, 19.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3183\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.1ms\n",
            "Speed: 3.5ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3184\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.5ms\n",
            "Speed: 3.6ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3185\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3186\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.4ms\n",
            "Speed: 7.7ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3187\n",
            "0: 384x640 1 Police, 1 Ambulance, 21.9ms\n",
            "Speed: 5.5ms preprocess, 21.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3188\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.7ms\n",
            "Speed: 4.7ms preprocess, 18.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3189\n",
            "0: 384x640 1 Police, 1 Ambulance, 22.0ms\n",
            "Speed: 3.6ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3190\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3191\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.6ms\n",
            "Speed: 5.7ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3192\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.6ms\n",
            "Speed: 5.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3193\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.1ms\n",
            "Speed: 10.2ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3194\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.8ms\n",
            "Speed: 6.6ms preprocess, 13.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3195\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3196\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3197\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 4.9ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3198\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.0ms\n",
            "Speed: 7.4ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3199\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.5ms\n",
            "Speed: 3.6ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3200\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3201\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.1ms\n",
            "Speed: 5.6ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3202\n",
            "0: 384x640 1 Police, 1 Ambulance, 22.2ms\n",
            "Speed: 4.3ms preprocess, 22.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3203\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.9ms\n",
            "Speed: 3.7ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3204\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.8ms\n",
            "Speed: 9.6ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3205\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3206\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3207\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3208\n",
            "0: 384x640 1 Police, 1 Ambulance, 18.2ms\n",
            "Speed: 5.2ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3209\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3210\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.3ms\n",
            "Speed: 4.7ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3210:\n",
            "- Detected Police with confidence: 0.57\n",
            "- Detected Ambulance with confidence: 0.34\n",
            "Processing frame 3211\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.6ms\n",
            "Speed: 4.5ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3212\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.5ms\n",
            "Speed: 3.7ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3213\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3214\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3215\n",
            "0: 384x640 1 Police, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3216\n",
            "0: 384x640 1 Police, 17.8ms\n",
            "Speed: 3.6ms preprocess, 17.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3217\n",
            "0: 384x640 1 Police, 15.4ms\n",
            "Speed: 13.3ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3218\n",
            "0: 384x640 1 Police, 16.3ms\n",
            "Speed: 3.9ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3219\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3220\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3221\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 5.6ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3222\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3223\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 3.7ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3224\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3225\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3226\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.8ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3227\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 10.4ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3228\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3229\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 3.6ms preprocess, 12.9ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3230\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 5.1ms preprocess, 15.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3231\n",
            "0: 384x640 1 Police, 13.5ms\n",
            "Speed: 3.8ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3232\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3233\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 5.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3234\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 6.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3235\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3236\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3237\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3238\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 7.7ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3239\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3240\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3240:\n",
            "- Detected Police with confidence: 0.38\n",
            "Processing frame 3241\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 3.4ms preprocess, 22.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3242\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 10.2ms preprocess, 16.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3243\n",
            "0: 384x640 1 Police, 15.4ms\n",
            "Speed: 5.8ms preprocess, 15.4ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3244\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 10.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3245\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 8.5ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3246\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 5.3ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3247\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 4.1ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3248\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 5.9ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3249\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 8.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3250\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3251\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.8ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3252\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.7ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3253\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3254\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3255\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3256\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 4.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3257\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 7.1ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3258\n",
            "0: 384x640 (no detections), 23.9ms\n",
            "Speed: 4.3ms preprocess, 23.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3259\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 5.0ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3260\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3261\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 4.1ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3262\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3263\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 6.5ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3264\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3265\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3266\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 3.8ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3267\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 3.9ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3268\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.9ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3269\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.9ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3270\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3270:\n",
            "Processing frame 3271\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 5.2ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3272\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3273\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 4.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3274\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 4.2ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3275\n",
            "0: 384x640 (no detections), 19.6ms\n",
            "Speed: 7.7ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3276\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3277\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3278\n",
            "0: 384x640 (no detections), 19.7ms\n",
            "Speed: 4.3ms preprocess, 19.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3279\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3280\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3281\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 4.9ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3282\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3283\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 5.1ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3284\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3285\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3286\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 4.9ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3287\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3288\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 4.3ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3289\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 6.1ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3290\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3291\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 3.9ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3292\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3293\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 5.0ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3294\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3295\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3296\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3297\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 4.8ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3298\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3299\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.7ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3300\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 4.0ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3300:\n",
            "Processing frame 3301\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3302\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 9.0ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3303\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 4.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3304\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 5.5ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3305\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 4.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3306\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 5.3ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3307\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3308\n",
            "0: 384x640 (no detections), 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3309\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3310\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3311\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 3.7ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3312\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 3.7ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3313\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3314\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.6ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3315\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 8.8ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3316\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3317\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 7.4ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3318\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3319\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 5.0ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3320\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 3.6ms preprocess, 18.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3321\n",
            "0: 384x640 (no detections), 20.2ms\n",
            "Speed: 5.2ms preprocess, 20.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3322\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 5.5ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3323\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 5.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3324\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3325\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 4.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3326\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3327\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3328\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3329\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 6.8ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3330\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 8.7ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3330:\n",
            "Processing frame 3331\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 5.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3332\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 3.6ms preprocess, 16.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3333\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3334\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3335\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 5.0ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3336\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 15.7ms preprocess, 18.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3337\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 4.2ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3338\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3339\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3340\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3341\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 4.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3342\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3343\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 7.3ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3344\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 7.1ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3345\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 3.9ms preprocess, 17.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3346\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 6.3ms preprocess, 19.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3347\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 3.6ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3348\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 5.1ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3349\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 3.8ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3350\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 4.2ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3351\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 5.6ms preprocess, 13.3ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3352\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 4.5ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3353\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3354\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3355\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 7.9ms preprocess, 18.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3356\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 6.3ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3357\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3358\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3359\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 3.5ms preprocess, 17.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3360\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3360:\n",
            "Processing frame 3361\n",
            "0: 384x640 1 Police, 20.4ms\n",
            "Speed: 3.5ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3362\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3363\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 4.5ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3364\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.6ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3365\n",
            "0: 384x640 1 Police, 21.4ms\n",
            "Speed: 6.6ms preprocess, 21.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3366\n",
            "0: 384x640 1 Police, 13.5ms\n",
            "Speed: 5.8ms preprocess, 13.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3367\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 8.5ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3368\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 6.0ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3369\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3370\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 3.7ms preprocess, 20.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3371\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3372\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 6.1ms preprocess, 11.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3373\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3374\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 8.8ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3375\n",
            "0: 384x640 1 Police, 17.0ms\n",
            "Speed: 4.6ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3376\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 4.9ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3377\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 6.2ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3378\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 7.7ms preprocess, 16.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3379\n",
            "0: 384x640 1 Police, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3380\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 4.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3381\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 7.2ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3382\n",
            "0: 384x640 1 Police, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3383\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3384\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 5.5ms preprocess, 19.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3385\n",
            "0: 384x640 (no detections), 24.8ms\n",
            "Speed: 4.3ms preprocess, 24.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3386\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 3.7ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3387\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3388\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 4.5ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3389\n",
            "0: 384x640 1 Police, 14.6ms\n",
            "Speed: 6.6ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3390\n",
            "0: 384x640 1 Police, 20.3ms\n",
            "Speed: 6.3ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3390:\n",
            "- Detected Police with confidence: 0.30\n",
            "Processing frame 3391\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 3.4ms preprocess, 20.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3392\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3393\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 5.6ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3394\n",
            "0: 384x640 (no detections), 21.5ms\n",
            "Speed: 3.6ms preprocess, 21.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3395\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 3.7ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3396\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 7.4ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3397\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 3.3ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3398\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 7.3ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3399\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3400\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3401\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3402\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.6ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3403\n",
            "0: 384x640 (no detections), 33.3ms\n",
            "Speed: 5.8ms preprocess, 33.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3404\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 3.6ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3405\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3406\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 3.6ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3407\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3408\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 8.0ms preprocess, 9.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3409\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 5.5ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3410\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3411\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 6.6ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3412\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3413\n",
            "0: 384x640 (no detections), 21.4ms\n",
            "Speed: 3.7ms preprocess, 21.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3414\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 4.2ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3415\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 4.5ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3416\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 4.9ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3417\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 4.5ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3418\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 6.8ms preprocess, 17.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3419\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 3.8ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3420\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 3.5ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3420:\n",
            "Processing frame 3421\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 3.7ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3422\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3423\n",
            "0: 384x640 (no detections), 25.6ms\n",
            "Speed: 3.5ms preprocess, 25.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3424\n",
            "0: 384x640 1 Police, 17.0ms\n",
            "Speed: 3.4ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3425\n",
            "0: 384x640 1 Police, 15.0ms\n",
            "Speed: 3.6ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3426\n",
            "0: 384x640 1 Police, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3427\n",
            "0: 384x640 1 Police, 19.6ms\n",
            "Speed: 5.9ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3428\n",
            "0: 384x640 1 Police, 17.1ms\n",
            "Speed: 6.6ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3429\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 6.5ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3430\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3431\n",
            "0: 384x640 1 Police, 21.6ms\n",
            "Speed: 9.6ms preprocess, 21.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3432\n",
            "0: 384x640 1 Police, 21.0ms\n",
            "Speed: 5.6ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3433\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 5.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3434\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 5.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3435\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 4.9ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3436\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3437\n",
            "0: 384x640 1 Police, 15.0ms\n",
            "Speed: 3.6ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3438\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 3.7ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3439\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 4.2ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3440\n",
            "0: 384x640 1 Police, 18.6ms\n",
            "Speed: 8.8ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3441\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 5.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3442\n",
            "0: 384x640 1 Police, 11.4ms\n",
            "Speed: 5.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3443\n",
            "0: 384x640 1 Police, 16.9ms\n",
            "Speed: 4.7ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3444\n",
            "0: 384x640 1 Police, 21.7ms\n",
            "Speed: 5.7ms preprocess, 21.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3445\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3446\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 3.4ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3447\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3448\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3449\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3450\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3450:\n",
            "- Detected Police with confidence: 0.48\n",
            "Processing frame 3451\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 6.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3452\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3453\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 3.8ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3454\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3455\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3456\n",
            "0: 384x640 1 Police, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3457\n",
            "0: 384x640 1 Police, 21.3ms\n",
            "Speed: 3.4ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3458\n",
            "0: 384x640 1 Police, 27.3ms\n",
            "Speed: 9.6ms preprocess, 27.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3459\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3460\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3461\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3462\n",
            "0: 384x640 1 Police, 12.7ms\n",
            "Speed: 3.9ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3463\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3464\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3465\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 5.3ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3466\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3467\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3468\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3469\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3470\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3471\n",
            "0: 384x640 1 Police, 20.8ms\n",
            "Speed: 9.5ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3472\n",
            "0: 384x640 1 Police, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3473\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 6.6ms preprocess, 10.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3474\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3475\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 7.5ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3476\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.4ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3477\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3478\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3479\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3480\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3480:\n",
            "- Detected Police with confidence: 0.54\n",
            "Processing frame 3481\n",
            "0: 384x640 1 Police, 15.3ms\n",
            "Speed: 6.4ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3482\n",
            "0: 384x640 1 Police, 16.8ms\n",
            "Speed: 3.5ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3483\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 3.4ms preprocess, 17.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3484\n",
            "0: 384x640 1 Police, 12.3ms\n",
            "Speed: 5.6ms preprocess, 12.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3485\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 4.2ms preprocess, 14.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3486\n",
            "0: 384x640 1 Police, 14.0ms\n",
            "Speed: 3.5ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3487\n",
            "0: 384x640 1 Police, 18.8ms\n",
            "Speed: 6.1ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3488\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3489\n",
            "0: 384x640 1 Police, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3490\n",
            "0: 384x640 1 Police, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3491\n",
            "0: 384x640 1 Police, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3492\n",
            "0: 384x640 1 Police, 25.8ms\n",
            "Speed: 6.4ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3493\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 3.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3494\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 5.5ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3495\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 4.6ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3496\n",
            "0: 384x640 1 Police, 20.7ms\n",
            "Speed: 3.5ms preprocess, 20.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3497\n",
            "0: 384x640 1 Police, 16.1ms\n",
            "Speed: 6.6ms preprocess, 16.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3498\n",
            "0: 384x640 1 Police, 18.1ms\n",
            "Speed: 5.2ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3499\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 7.5ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3500\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 4.2ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3501\n",
            "0: 384x640 1 Police, 18.5ms\n",
            "Speed: 3.5ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3502\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 7.1ms preprocess, 11.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3503\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3504\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.6ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3505\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3506\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3507\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 4.5ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3508\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 4.2ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3509\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3510\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3510:\n",
            "- Detected Police with confidence: 0.51\n",
            "Processing frame 3511\n",
            "0: 384x640 1 Police, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3512\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 4.7ms preprocess, 15.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3513\n",
            "0: 384x640 1 Police, 21.4ms\n",
            "Speed: 3.6ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3514\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3515\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3516\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3517\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3518\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3519\n",
            "0: 384x640 1 Police, 11.6ms\n",
            "Speed: 3.5ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3520\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 3.6ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3521\n",
            "0: 384x640 1 Police, 18.0ms\n",
            "Speed: 6.0ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3522\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 3.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3523\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 4.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3524\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3525\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3526\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3527\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 8.8ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3528\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 15.0ms preprocess, 15.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3529\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3530\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 5.3ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3531\n",
            "0: 384x640 1 Police, 19.9ms\n",
            "Speed: 3.6ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3532\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 4.5ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3533\n",
            "0: 384x640 1 Police, 16.3ms\n",
            "Speed: 3.7ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3534\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3535\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3536\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3537\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 5.8ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3538\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3539\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 6.2ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3540\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3540:\n",
            "Processing frame 3541\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 7.8ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3542\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 7.2ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3543\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 3.5ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3544\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3545\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3546\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 4.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3547\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 4.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3548\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 3.6ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3549\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 3.7ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3550\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3551\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3552\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 4.9ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3553\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 8.0ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3554\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3555\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 5.1ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3556\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3557\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 5.3ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3558\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3559\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3560\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 7.6ms preprocess, 14.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3561\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 4.5ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3562\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 6.6ms preprocess, 16.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3563\n",
            "0: 384x640 (no detections), 19.4ms\n",
            "Speed: 3.5ms preprocess, 19.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3564\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 4.6ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3565\n",
            "0: 384x640 1 Police, 13.0ms\n",
            "Speed: 4.6ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3566\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 3.5ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3567\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 3.5ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3568\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 4.8ms preprocess, 18.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3569\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 4.7ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3570\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 4.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3570:\n",
            "Processing frame 3571\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 10.0ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3572\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 5.4ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3573\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3574\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 3.5ms preprocess, 18.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3575\n",
            "0: 384x640 (no detections), 21.3ms\n",
            "Speed: 12.6ms preprocess, 21.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3576\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3577\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 4.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3578\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 5.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3579\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 5.5ms preprocess, 17.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3580\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 3.5ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3581\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 5.4ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3582\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3583\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 5.8ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3584\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3585\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 5.4ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3586\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 3.9ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3587\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 4.1ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3588\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3589\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3590\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3591\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 5.3ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3592\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 3.5ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3593\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 8.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3594\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 5.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3595\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3596\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3597\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 4.9ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3598\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 4.7ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3599\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 4.5ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3600\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 3.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3600:\n",
            "Processing frame 3601\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 5.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3602\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 4.5ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3603\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3604\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 3.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3605\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.7ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3606\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3607\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3608\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 7.3ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3609\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3610\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 4.6ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3611\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 5.7ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3612\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 3.5ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3613\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 4.4ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3614\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 4.0ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3615\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 6.6ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3616\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3617\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 6.2ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3618\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 5.4ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3619\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 4.8ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3620\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 5.0ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3621\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 3.9ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3622\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3623\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 5.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3624\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3625\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3626\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3627\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 5.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3628\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 5.5ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3629\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 5.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3630\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 4.7ms preprocess, 18.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3630:\n",
            "- Detected Police with confidence: 0.40\n",
            "Processing frame 3631\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 4.8ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3632\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 3.7ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3633\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3634\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 5.6ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3635\n",
            "0: 384x640 1 Police, 14.5ms\n",
            "Speed: 6.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3636\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 4.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3637\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 10.9ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3638\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 6.8ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3639\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3640\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3641\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 3.9ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3642\n",
            "0: 384x640 1 Ambulance, 10.6ms\n",
            "Speed: 6.5ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3643\n",
            "0: 384x640 1 Police, 13.6ms\n",
            "Speed: 5.3ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3644\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 3.6ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3645\n",
            "0: 384x640 1 Ambulance, 19.0ms\n",
            "Speed: 3.9ms preprocess, 19.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3646\n",
            "0: 384x640 1 Ambulance, 11.9ms\n",
            "Speed: 3.8ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3647\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3648\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3649\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3650\n",
            "0: 384x640 1 Ambulance, 9.5ms\n",
            "Speed: 4.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3651\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.8ms\n",
            "Speed: 6.5ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3652\n",
            "0: 384x640 1 Ambulance, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3653\n",
            "0: 384x640 1 Ambulance, 9.6ms\n",
            "Speed: 3.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3654\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 4.1ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3655\n",
            "0: 384x640 1 Ambulance, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3656\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3657\n",
            "0: 384x640 1 Ambulance, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3658\n",
            "0: 384x640 1 Ambulance, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3659\n",
            "0: 384x640 1 Ambulance, 12.7ms\n",
            "Speed: 8.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3660\n",
            "0: 384x640 1 Ambulance, 16.0ms\n",
            "Speed: 7.8ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3660:\n",
            "- Detected Ambulance with confidence: 0.66\n",
            "Processing frame 3661\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3662\n",
            "0: 384x640 1 Ambulance, 11.3ms\n",
            "Speed: 7.6ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3663\n",
            "0: 384x640 1 Ambulance, 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3664\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3665\n",
            "0: 384x640 1 Ambulance, 10.6ms\n",
            "Speed: 5.3ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3666\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3667\n",
            "0: 384x640 1 Ambulance, 10.6ms\n",
            "Speed: 4.8ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3668\n",
            "0: 384x640 1 Police, 1 Ambulance, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3669\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3670\n",
            "0: 384x640 1 Ambulance, 12.2ms\n",
            "Speed: 7.7ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3671\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 4.6ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3672\n",
            "0: 384x640 1 Ambulance, 12.4ms\n",
            "Speed: 6.3ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3673\n",
            "0: 384x640 1 Ambulance, 13.9ms\n",
            "Speed: 4.3ms preprocess, 13.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3674\n",
            "0: 384x640 1 Ambulance, 12.2ms\n",
            "Speed: 7.0ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3675\n",
            "0: 384x640 1 Ambulance, 19.7ms\n",
            "Speed: 5.1ms preprocess, 19.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3676\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 7.2ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3677\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 4.5ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3678\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3679\n",
            "0: 384x640 1 Ambulance, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3680\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3681\n",
            "0: 384x640 1 Ambulance, 18.7ms\n",
            "Speed: 3.6ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3682\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3683\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.4ms\n",
            "Speed: 4.1ms preprocess, 14.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3684\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.0ms\n",
            "Speed: 5.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3685\n",
            "0: 384x640 1 Police, 1 Ambulance, 12.9ms\n",
            "Speed: 3.8ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3686\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3687\n",
            "0: 384x640 1 Police, 1 Ambulance, 8.8ms\n",
            "Speed: 4.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3688\n",
            "0: 384x640 1 Police, 20.0ms\n",
            "Speed: 4.4ms preprocess, 20.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3689\n",
            "0: 384x640 1 Ambulance, 19.4ms\n",
            "Speed: 6.3ms preprocess, 19.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3690\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.7ms\n",
            "Speed: 6.2ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3690:\n",
            "- Detected Police with confidence: 0.53\n",
            "- Detected Ambulance with confidence: 0.37\n",
            "Processing frame 3691\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3692\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 5.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3693\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 5.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3694\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 6.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3695\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 6.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3696\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3697\n",
            "0: 384x640 1 Police, 8.9ms\n",
            "Speed: 5.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3698\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3699\n",
            "0: 384x640 1 Police, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3700\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3701\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3702\n",
            "0: 384x640 1 Police, 18.2ms\n",
            "Speed: 4.4ms preprocess, 18.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3703\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 3.7ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3704\n",
            "0: 384x640 1 Police, 13.2ms\n",
            "Speed: 5.1ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3705\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 5.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3706\n",
            "0: 384x640 1 Police, 9.1ms\n",
            "Speed: 5.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3707\n",
            "0: 384x640 1 Police, 15.1ms\n",
            "Speed: 3.5ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3708\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 4.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3709\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3710\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 3.6ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3711\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3712\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3713\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3714\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.8ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3715\n",
            "0: 384x640 1 Police, 15.6ms\n",
            "Speed: 8.6ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3716\n",
            "0: 384x640 1 Police, 14.2ms\n",
            "Speed: 5.9ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3717\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 4.0ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3718\n",
            "0: 384x640 1 Police, 13.5ms\n",
            "Speed: 3.8ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3719\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3720\n",
            "0: 384x640 1 Police, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3720:\n",
            "- Detected Police with confidence: 0.59\n",
            "Processing frame 3721\n",
            "0: 384x640 1 Police, 12.2ms\n",
            "Speed: 3.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3722\n",
            "0: 384x640 1 Police, 27.2ms\n",
            "Speed: 3.6ms preprocess, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3723\n",
            "0: 384x640 1 Police, 9.2ms\n",
            "Speed: 5.0ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3724\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3725\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3726\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3727\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 4.3ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3728\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 4.8ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3729\n",
            "0: 384x640 1 Police, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3730\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 7.9ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3731\n",
            "0: 384x640 1 Police, 13.6ms\n",
            "Speed: 3.7ms preprocess, 13.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3732\n",
            "0: 384x640 1 Police, 19.2ms\n",
            "Speed: 3.6ms preprocess, 19.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3733\n",
            "0: 384x640 1 Police, 16.6ms\n",
            "Speed: 3.5ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3734\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3735\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3736\n",
            "0: 384x640 1 Police, 14.5ms\n",
            "Speed: 4.6ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3737\n",
            "0: 384x640 1 Police, 14.5ms\n",
            "Speed: 3.6ms preprocess, 14.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3738\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3739\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 3.5ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3740\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 3.7ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3741\n",
            "0: 384x640 1 Police, 18.9ms\n",
            "Speed: 3.6ms preprocess, 18.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3742\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 4.9ms preprocess, 13.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3743\n",
            "0: 384x640 1 Police, 16.3ms\n",
            "Speed: 9.0ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3744\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3745\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3746\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3747\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 3.6ms preprocess, 12.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3748\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 6.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3749\n",
            "0: 384x640 1 Police, 15.4ms\n",
            "Speed: 4.1ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3750\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 4.7ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3750:\n",
            "- Detected Police with confidence: 0.64\n",
            "Processing frame 3751\n",
            "0: 384x640 1 Police, 22.7ms\n",
            "Speed: 3.5ms preprocess, 22.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3752\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 4.9ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3753\n",
            "0: 384x640 1 Police, 17.7ms\n",
            "Speed: 5.4ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3754\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 5.4ms preprocess, 12.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3755\n",
            "0: 384x640 1 Police, 21.0ms\n",
            "Speed: 3.7ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3756\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.7ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3757\n",
            "0: 384x640 1 Police, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3758\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 3.6ms preprocess, 14.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3759\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 5.0ms preprocess, 15.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3760\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3761\n",
            "0: 384x640 1 Police, 20.6ms\n",
            "Speed: 3.5ms preprocess, 20.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3762\n",
            "0: 384x640 1 Police, 18.6ms\n",
            "Speed: 3.4ms preprocess, 18.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3763\n",
            "0: 384x640 1 Police, 17.8ms\n",
            "Speed: 3.4ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3764\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3765\n",
            "0: 384x640 1 Police, 11.6ms\n",
            "Speed: 6.8ms preprocess, 11.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3766\n",
            "0: 384x640 1 Police, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3767\n",
            "0: 384x640 1 Police, 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3768\n",
            "0: 384x640 1 Police, 16.5ms\n",
            "Speed: 7.0ms preprocess, 16.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3769\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3770\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3771\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 6.5ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3772\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3773\n",
            "0: 384x640 1 Police, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3774\n",
            "0: 384x640 1 Police, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3775\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3776\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3777\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3778\n",
            "0: 384x640 1 Police, 13.2ms\n",
            "Speed: 5.5ms preprocess, 13.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3779\n",
            "0: 384x640 1 Police, 14.0ms\n",
            "Speed: 3.5ms preprocess, 14.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3780\n",
            "0: 384x640 1 Police, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3780:\n",
            "- Detected Police with confidence: 0.64\n",
            "Processing frame 3781\n",
            "0: 384x640 1 Police, 18.9ms\n",
            "Speed: 5.9ms preprocess, 18.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3782\n",
            "0: 384x640 1 Police, 23.0ms\n",
            "Speed: 3.6ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3783\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 5.1ms preprocess, 18.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3784\n",
            "0: 384x640 1 Police, 19.8ms\n",
            "Speed: 3.5ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3785\n",
            "0: 384x640 1 Police, 18.7ms\n",
            "Speed: 3.6ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3786\n",
            "0: 384x640 1 Police, 16.9ms\n",
            "Speed: 4.5ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3787\n",
            "0: 384x640 1 Police, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3788\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3789\n",
            "0: 384x640 1 Police, 9.3ms\n",
            "Speed: 4.7ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3790\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3791\n",
            "0: 384x640 1 Police, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3792\n",
            "0: 384x640 1 Police, 20.6ms\n",
            "Speed: 4.6ms preprocess, 20.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3793\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 8.3ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3794\n",
            "0: 384x640 1 Police, 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3795\n",
            "0: 384x640 1 Police, 21.7ms\n",
            "Speed: 3.6ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3796\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 4.9ms preprocess, 15.9ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3797\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 3.6ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3798\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3799\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3800\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 6.7ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3801\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 6.3ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3802\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 4.1ms preprocess, 10.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3803\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 4.2ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3804\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3805\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 5.7ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3806\n",
            "0: 384x640 1 Police, 19.4ms\n",
            "Speed: 3.6ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3807\n",
            "0: 384x640 1 Police, 17.8ms\n",
            "Speed: 3.4ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3808\n",
            "0: 384x640 1 Police, 16.4ms\n",
            "Speed: 9.0ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3809\n",
            "0: 384x640 1 Police, 17.0ms\n",
            "Speed: 3.5ms preprocess, 17.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3810\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.8ms\n",
            "Speed: 4.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3810:\n",
            "- Detected Police with confidence: 0.47\n",
            "- Detected Ambulance with confidence: 0.32\n",
            "Processing frame 3811\n",
            "0: 384x640 1 Police, 13.1ms\n",
            "Speed: 6.9ms preprocess, 13.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3812\n",
            "0: 384x640 1 Police, 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3813\n",
            "0: 384x640 1 Police, 23.0ms\n",
            "Speed: 3.8ms preprocess, 23.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3814\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3815\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3816\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3817\n",
            "0: 384x640 1 Police, 20.6ms\n",
            "Speed: 3.4ms preprocess, 20.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3818\n",
            "0: 384x640 1 Police, 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3819\n",
            "0: 384x640 1 Police, 16.5ms\n",
            "Speed: 3.6ms preprocess, 16.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3820\n",
            "0: 384x640 1 Police, 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3821\n",
            "0: 384x640 1 Police, 1 Ambulance, 16.9ms\n",
            "Speed: 7.0ms preprocess, 16.9ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3822\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.6ms\n",
            "Speed: 4.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3823\n",
            "0: 384x640 1 Police, 1 Ambulance, 20.3ms\n",
            "Speed: 3.6ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3824\n",
            "0: 384x640 1 Police, 1 Ambulance, 14.8ms\n",
            "Speed: 4.1ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3825\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3826\n",
            "0: 384x640 1 Police, 12.1ms\n",
            "Speed: 10.6ms preprocess, 12.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3827\n",
            "0: 384x640 1 Police, 1 Ambulance, 13.4ms\n",
            "Speed: 6.6ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3828\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 6.3ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3829\n",
            "0: 384x640 1 Police, 9.7ms\n",
            "Speed: 4.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3830\n",
            "0: 384x640 1 Police, 13.8ms\n",
            "Speed: 6.8ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3831\n",
            "0: 384x640 1 Police, 1 Ambulance, 24.2ms\n",
            "Speed: 3.6ms preprocess, 24.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3832\n",
            "0: 384x640 1 Police, 1 Ambulance, 23.0ms\n",
            "Speed: 4.7ms preprocess, 23.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3833\n",
            "0: 384x640 1 Police, 18.6ms\n",
            "Speed: 5.5ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3834\n",
            "0: 384x640 1 Police, 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3835\n",
            "0: 384x640 1 Police, 18.1ms\n",
            "Speed: 7.5ms preprocess, 18.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3836\n",
            "0: 384x640 1 Police, 16.8ms\n",
            "Speed: 4.1ms preprocess, 16.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3837\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3838\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 7.2ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3839\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3840\n",
            "0: 384x640 1 Police, 1 Ambulance, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3840:\n",
            "- Detected Police with confidence: 0.46\n",
            "- Detected Ambulance with confidence: 0.41\n",
            "Processing frame 3841\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.8ms\n",
            "Speed: 4.3ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3842\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3843\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 4.2ms preprocess, 16.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3844\n",
            "0: 384x640 1 Police, 19.6ms\n",
            "Speed: 3.3ms preprocess, 19.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3845\n",
            "0: 384x640 1 Police, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3846\n",
            "0: 384x640 1 Police, 19.5ms\n",
            "Speed: 5.8ms preprocess, 19.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3847\n",
            "0: 384x640 1 Police, 15.8ms\n",
            "Speed: 3.6ms preprocess, 15.8ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3848\n",
            "0: 384x640 1 Police, 18.7ms\n",
            "Speed: 3.5ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3849\n",
            "0: 384x640 1 Police, 10.6ms\n",
            "Speed: 6.3ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3850\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 4.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3851\n",
            "0: 384x640 1 Police, 19.5ms\n",
            "Speed: 3.5ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3852\n",
            "0: 384x640 1 Police, 1 Ambulance, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3853\n",
            "0: 384x640 1 Police, 16.2ms\n",
            "Speed: 5.4ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3854\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 5.6ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3855\n",
            "0: 384x640 1 Police, 19.5ms\n",
            "Speed: 3.5ms preprocess, 19.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3856\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 4.7ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3857\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 4.5ms preprocess, 18.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3858\n",
            "0: 384x640 1 Police, 10.9ms\n",
            "Speed: 5.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3859\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3860\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 5.9ms preprocess, 14.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3861\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.6ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3862\n",
            "0: 384x640 1 Police, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3863\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3864\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 7.1ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3865\n",
            "0: 384x640 1 Police, 20.2ms\n",
            "Speed: 3.8ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3866\n",
            "0: 384x640 1 Police, 20.0ms\n",
            "Speed: 4.1ms preprocess, 20.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3867\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3868\n",
            "0: 384x640 1 Police, 17.3ms\n",
            "Speed: 3.6ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3869\n",
            "0: 384x640 1 Police, 19.9ms\n",
            "Speed: 9.0ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3870\n",
            "0: 384x640 1 Police, 13.0ms\n",
            "Speed: 6.0ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3870:\n",
            "- Detected Police with confidence: 0.55\n",
            "Processing frame 3871\n",
            "0: 384x640 1 Police, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3872\n",
            "0: 384x640 1 Police, 13.6ms\n",
            "Speed: 3.5ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3873\n",
            "0: 384x640 1 Police, 19.1ms\n",
            "Speed: 4.0ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3874\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 6.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3875\n",
            "0: 384x640 1 Police, 17.3ms\n",
            "Speed: 3.5ms preprocess, 17.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3876\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 6.7ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3877\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.7ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3878\n",
            "0: 384x640 1 Police, 15.1ms\n",
            "Speed: 4.4ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3879\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 8.5ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3880\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3881\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 3.6ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3882\n",
            "0: 384x640 1 Police, 12.4ms\n",
            "Speed: 4.9ms preprocess, 12.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3883\n",
            "0: 384x640 1 Police, 16.1ms\n",
            "Speed: 5.3ms preprocess, 16.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3884\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3885\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 11.6ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3886\n",
            "0: 384x640 1 Police, 18.6ms\n",
            "Speed: 3.9ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3887\n",
            "0: 384x640 1 Police, 16.4ms\n",
            "Speed: 4.3ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3888\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 4.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3889\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 4.4ms preprocess, 12.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3890\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 6.9ms preprocess, 14.1ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3891\n",
            "0: 384x640 1 Police, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3892\n",
            "0: 384x640 1 Police, 12.5ms\n",
            "Speed: 4.1ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3893\n",
            "0: 384x640 1 Police, 17.2ms\n",
            "Speed: 3.5ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3894\n",
            "0: 384x640 1 Police, 13.3ms\n",
            "Speed: 3.6ms preprocess, 13.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3895\n",
            "0: 384x640 1 Police, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3896\n",
            "0: 384x640 1 Police, 20.3ms\n",
            "Speed: 3.6ms preprocess, 20.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3897\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 9.2ms preprocess, 17.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3898\n",
            "0: 384x640 1 Police, 18.4ms\n",
            "Speed: 3.7ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3899\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 5.8ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3900\n",
            "0: 384x640 1 Police, 15.7ms\n",
            "Speed: 5.3ms preprocess, 15.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3900:\n",
            "- Detected Police with confidence: 0.64\n",
            "Processing frame 3901\n",
            "0: 384x640 1 Police, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3902\n",
            "0: 384x640 1 Police, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3903\n",
            "0: 384x640 1 Police, 19.3ms\n",
            "Speed: 3.5ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3904\n",
            "0: 384x640 1 Police, 15.0ms\n",
            "Speed: 3.5ms preprocess, 15.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3905\n",
            "0: 384x640 1 Police, 14.4ms\n",
            "Speed: 3.1ms preprocess, 14.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3906\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3907\n",
            "0: 384x640 1 Police, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3908\n",
            "0: 384x640 1 Police, 15.1ms\n",
            "Speed: 5.9ms preprocess, 15.1ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3909\n",
            "0: 384x640 1 Police, 19.9ms\n",
            "Speed: 3.7ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3910\n",
            "0: 384x640 1 Police, 14.0ms\n",
            "Speed: 7.5ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3911\n",
            "0: 384x640 1 Police, 16.7ms\n",
            "Speed: 3.4ms preprocess, 16.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3912\n",
            "0: 384x640 1 Police, 18.5ms\n",
            "Speed: 3.6ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3913\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3914\n",
            "0: 384x640 1 Police, 16.5ms\n",
            "Speed: 3.6ms preprocess, 16.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3915\n",
            "0: 384x640 1 Police, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3916\n",
            "0: 384x640 1 Police, 16.2ms\n",
            "Speed: 7.5ms preprocess, 16.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3917\n",
            "0: 384x640 1 Police, 12.8ms\n",
            "Speed: 5.4ms preprocess, 12.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3918\n",
            "0: 384x640 1 Police, 16.1ms\n",
            "Speed: 3.4ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3919\n",
            "0: 384x640 1 Police, 16.2ms\n",
            "Speed: 3.6ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3920\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 4.9ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3921\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 4.7ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3922\n",
            "0: 384x640 1 Police, 20.3ms\n",
            "Speed: 5.1ms preprocess, 20.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3923\n",
            "0: 384x640 1 Police, 18.7ms\n",
            "Speed: 5.6ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3924\n",
            "0: 384x640 1 Police, 22.2ms\n",
            "Speed: 3.7ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3925\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 3.5ms preprocess, 15.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3926\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 5.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3927\n",
            "0: 384x640 1 Police, 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3928\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3929\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3930\n",
            "0: 384x640 1 Police, 19.4ms\n",
            "Speed: 3.3ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3930:\n",
            "- Detected Police with confidence: 0.60\n",
            "Processing frame 3931\n",
            "0: 384x640 1 Police, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3932\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 4.4ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3933\n",
            "0: 384x640 1 Police, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3934\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3935\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3936\n",
            "0: 384x640 1 Police, 9.8ms\n",
            "Speed: 5.1ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3937\n",
            "0: 384x640 1 Police, 11.3ms\n",
            "Speed: 4.8ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3938\n",
            "0: 384x640 1 Police, 15.1ms\n",
            "Speed: 9.1ms preprocess, 15.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3939\n",
            "0: 384x640 1 Police, 13.8ms\n",
            "Speed: 4.6ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3940\n",
            "0: 384x640 1 Police, 14.3ms\n",
            "Speed: 4.9ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3941\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 5.3ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3942\n",
            "0: 384x640 1 Police, 10.0ms\n",
            "Speed: 3.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3943\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3944\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 4.2ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3945\n",
            "0: 384x640 1 Police, 9.6ms\n",
            "Speed: 4.6ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3946\n",
            "0: 384x640 1 Police, 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3947\n",
            "0: 384x640 1 Police, 15.5ms\n",
            "Speed: 3.7ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3948\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 4.7ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3949\n",
            "0: 384x640 1 Police, 10.4ms\n",
            "Speed: 4.9ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3950\n",
            "0: 384x640 1 Police, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3951\n",
            "0: 384x640 1 Police, 8.5ms\n",
            "Speed: 3.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3952\n",
            "0: 384x640 1 Police, 12.3ms\n",
            "Speed: 3.7ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3953\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 5.7ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3954\n",
            "0: 384x640 1 Police, 14.1ms\n",
            "Speed: 4.2ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3955\n",
            "0: 384x640 1 Police, 14.6ms\n",
            "Speed: 5.3ms preprocess, 14.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3956\n",
            "0: 384x640 1 Police, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3957\n",
            "0: 384x640 1 Police, 15.0ms\n",
            "Speed: 3.5ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3958\n",
            "0: 384x640 1 Police, 18.3ms\n",
            "Speed: 4.2ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3959\n",
            "0: 384x640 1 Police, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3960\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3960:\n",
            "- Detected Police with confidence: 0.67\n",
            "Processing frame 3961\n",
            "0: 384x640 1 Police, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3962\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3963\n",
            "0: 384x640 1 Police, 13.6ms\n",
            "Speed: 8.2ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3964\n",
            "0: 384x640 1 Police, 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3965\n",
            "0: 384x640 1 Police, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3966\n",
            "0: 384x640 1 Police, 10.2ms\n",
            "Speed: 3.8ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3967\n",
            "0: 384x640 1 Police, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3968\n",
            "0: 384x640 1 Police, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3969\n",
            "0: 384x640 1 Police, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3970\n",
            "0: 384x640 1 Police, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3971\n",
            "0: 384x640 1 Police, 12.0ms\n",
            "Speed: 3.7ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3972\n",
            "0: 384x640 1 Police, 18.2ms\n",
            "Speed: 4.6ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3973\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 4.6ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3974\n",
            "0: 384x640 1 Police, 12.9ms\n",
            "Speed: 3.7ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3975\n",
            "0: 384x640 1 Police, 8.5ms\n",
            "Speed: 4.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3976\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3977\n",
            "0: 384x640 1 Police, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3978\n",
            "0: 384x640 1 Police, 17.4ms\n",
            "Speed: 3.6ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3979\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3980\n",
            "0: 384x640 1 Police, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3981\n",
            "0: 384x640 1 Police, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3982\n",
            "0: 384x640 1 Police, 15.9ms\n",
            "Speed: 3.9ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3983\n",
            "0: 384x640 1 Police, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3984\n",
            "0: 384x640 1 Police, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3985\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3986\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3987\n",
            "0: 384x640 1 Police, 1 Ambulance, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3988\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.7ms\n",
            "Speed: 3.8ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3989\n",
            "0: 384x640 1 Police, 1 Ambulance, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3990\n",
            "0: 384x640 1 Ambulance, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 3990:\n",
            "- Detected Ambulance with confidence: 0.48\n",
            "Processing frame 3991\n",
            "0: 384x640 1 Ambulance, 10.0ms\n",
            "Speed: 5.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3992\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 3.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3993\n",
            "0: 384x640 1 Ambulance, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3994\n",
            "0: 384x640 1 Ambulance, 9.5ms\n",
            "Speed: 4.8ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3995\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 7.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3996\n",
            "0: 384x640 1 Ambulance, 8.7ms\n",
            "Speed: 5.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3997\n",
            "0: 384x640 1 Ambulance, 14.0ms\n",
            "Speed: 3.3ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3998\n",
            "0: 384x640 1 Ambulance, 8.6ms\n",
            "Speed: 4.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3999\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 4.6ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4000\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 4.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4001\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4002\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4003\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 5.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4004\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 4.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4005\n",
            "0: 384x640 1 Ambulance, 13.2ms\n",
            "Speed: 6.3ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4006\n",
            "0: 384x640 1 Ambulance, 13.2ms\n",
            "Speed: 3.8ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4007\n",
            "0: 384x640 1 Ambulance, 16.1ms\n",
            "Speed: 4.7ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4008\n",
            "0: 384x640 1 Ambulance, 11.0ms\n",
            "Speed: 6.1ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4009\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 4.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4010\n",
            "0: 384x640 1 Ambulance, 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4011\n",
            "0: 384x640 1 Ambulance, 8.7ms\n",
            "Speed: 4.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4012\n",
            "0: 384x640 1 Ambulance, 8.7ms\n",
            "Speed: 4.6ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4013\n",
            "0: 384x640 1 Ambulance, 8.5ms\n",
            "Speed: 4.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4014\n",
            "0: 384x640 1 Ambulance, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4015\n",
            "0: 384x640 1 Ambulance, 16.5ms\n",
            "Speed: 4.4ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4016\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 4.4ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4017\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 4.2ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4018\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 4.4ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4019\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 4.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4020\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 4.6ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 4020:\n",
            "- Detected Ambulance with confidence: 0.63\n",
            "Processing frame 4021\n",
            "0: 384x640 1 Ambulance, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4022\n",
            "0: 384x640 1 Ambulance, 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4023\n",
            "0: 384x640 1 Ambulance, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4024\n",
            "0: 384x640 1 Ambulance, 14.8ms\n",
            "Speed: 4.4ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4025\n",
            "0: 384x640 1 Ambulance, 28.8ms\n",
            "Speed: 5.5ms preprocess, 28.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4026\n",
            "0: 384x640 1 Ambulance, 16.1ms\n",
            "Speed: 4.9ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4027\n",
            "0: 384x640 1 Ambulance, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4028\n",
            "0: 384x640 1 Ambulance, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4029\n",
            "0: 384x640 1 Ambulance, 10.0ms\n",
            "Speed: 7.4ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4030\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4031\n",
            "0: 384x640 1 Ambulance, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4032\n",
            "0: 384x640 1 Ambulance, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4033\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 3.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4034\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4035\n",
            "0: 384x640 1 Ambulance, 14.6ms\n",
            "Speed: 7.4ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4036\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4037\n",
            "0: 384x640 1 Ambulance, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4038\n",
            "0: 384x640 1 Ambulance, 11.8ms\n",
            "Speed: 7.1ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4039\n",
            "0: 384x640 1 Ambulance, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4040\n",
            "0: 384x640 1 Ambulance, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4041\n",
            "0: 384x640 1 Ambulance, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4042\n",
            "0: 384x640 1 Ambulance, 12.3ms\n",
            "Speed: 3.7ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4043\n",
            "0: 384x640 1 Ambulance, 16.7ms\n",
            "Speed: 3.6ms preprocess, 16.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4044\n",
            "0: 384x640 1 Ambulance, 10.1ms\n",
            "Speed: 4.4ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4045\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4046\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 4.6ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4047\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 4.7ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4048\n",
            "0: 384x640 1 Ambulance, 8.6ms\n",
            "Speed: 3.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4049\n",
            "0: 384x640 1 Ambulance, 9.1ms\n",
            "Speed: 4.6ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4050\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 5.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 4050:\n",
            "- Detected Ambulance with confidence: 0.63\n",
            "Processing frame 4051\n",
            "0: 384x640 1 Ambulance, 9.1ms\n",
            "Speed: 3.8ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4052\n",
            "0: 384x640 1 Ambulance, 10.1ms\n",
            "Speed: 7.2ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4053\n",
            "0: 384x640 1 Ambulance, 11.9ms\n",
            "Speed: 7.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4054\n",
            "0: 384x640 1 Ambulance, 9.7ms\n",
            "Speed: 4.4ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4055\n",
            "0: 384x640 1 Ambulance, 12.1ms\n",
            "Speed: 4.5ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4056\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4057\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4058\n",
            "0: 384x640 1 Ambulance, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4059\n",
            "0: 384x640 1 Ambulance, 17.2ms\n",
            "Speed: 7.4ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4060\n",
            "0: 384x640 1 Ambulance, 10.9ms\n",
            "Speed: 4.8ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4061\n",
            "0: 384x640 1 Ambulance, 16.9ms\n",
            "Speed: 4.6ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4062\n",
            "0: 384x640 1 Ambulance, 17.6ms\n",
            "Speed: 4.2ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4063\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4064\n",
            "0: 384x640 1 Ambulance, 14.6ms\n",
            "Speed: 3.7ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4065\n",
            "0: 384x640 1 Ambulance, 13.5ms\n",
            "Speed: 3.4ms preprocess, 13.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4066\n",
            "0: 384x640 1 Ambulance, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4067\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 5.1ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4068\n",
            "0: 384x640 1 Ambulance, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4069\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 5.7ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4070\n",
            "0: 384x640 1 Ambulance, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4071\n",
            "0: 384x640 1 Ambulance, 9.6ms\n",
            "Speed: 4.6ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4072\n",
            "0: 384x640 1 Ambulance, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4073\n",
            "0: 384x640 1 Ambulance, 8.5ms\n",
            "Speed: 5.1ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4074\n",
            "0: 384x640 1 Ambulance, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4075\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4076\n",
            "0: 384x640 1 Ambulance, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4077\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4078\n",
            "0: 384x640 1 Ambulance, 15.1ms\n",
            "Speed: 5.0ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4079\n",
            "0: 384x640 1 Ambulance, 19.2ms\n",
            "Speed: 5.7ms preprocess, 19.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4080\n",
            "0: 384x640 1 Ambulance, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Detections in frame 4080:\n",
            "- Detected Ambulance with confidence: 0.63\n",
            "Processing frame 4081\n",
            "0: 384x640 1 Ambulance, 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4082\n",
            "0: 384x640 1 Ambulance, 9.8ms\n",
            "Speed: 4.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4083\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 5.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4084\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 7.9ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4085\n",
            "0: 384x640 1 Ambulance, 8.8ms\n",
            "Speed: 4.9ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4086\n",
            "0: 384x640 1 Ambulance, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4087\n",
            "0: 384x640 1 Ambulance, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4088\n",
            "0: 384x640 1 Ambulance, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4089\n",
            "0: 384x640 1 Ambulance, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4090\n",
            "0: 384x640 1 Ambulance, 10.2ms\n",
            "Speed: 5.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Processed 4090 frames\n",
            "Saved detected video to /content/drive/MyDrive/yolo_results/Fire engine in Delhiï¼š Traffic on a winter morning in Delhi [Way0mXOFXk0]_detected.mp4\n",
            "Saved key frames to /content/drive/MyDrive/yolo_results/Fire engine in Delhiï¼š Traffic on a winter morning in Delhi [Way0mXOFXk0]_frames\n",
            "\n",
            "Detection Statistics:\n",
            "Police: 3514 detections\n",
            "Fire_Engine: 0 detections\n",
            "Ambulance: 532 detections\n",
            "\n",
            "All results saved to /content/drive/MyDrive/yolo_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QY9J2_LaQeLh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}